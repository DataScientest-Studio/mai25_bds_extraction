{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0d0807ef-5aea-4645-b830-79bdbb529480",
   "metadata": {},
   "source": [
    "# Table of Contents\n",
    "* [Importer les librairies et dataframes](#c1)\n",
    "* [Exploration de chaque caractéristique extraite](#c2)\n",
    "    * [Creation des fonctions nécessaires](#s2_0)\n",
    "    * [Largeur](#s2_1)\n",
    "    * [Netteté](#s2_2)\n",
    "    * [Bruit](#s2_3)\n",
    "    * [Ratio pixels blancs / total](#s2_4)\n",
    "    * [Ratio pixels noirs / total](#s2_5)\n",
    "* [Répartitions dans les différents sets](#c3)\n",
    "* [Corrélation entre les caractéristiques](#c4)\n",
    "    * [Heatmap des corrélations](#s4_1)\n",
    "    * [Scatter plots et courbes de densite](#s4_2)\n",
    "* [LDA](#c5)\n",
    "* [Comparaison avec IIT](#c5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fd749dd-0efb-4707-9382-858898ba8c78",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Importer les librairies et dataframes <a class=\"anchor\" id=\"c1\"></a>\n",
    "\n",
    "On importe ici 5 documents:\n",
    "- train.txt, test.txt et val.txt, pour récupérer, pour chaque image, sa catégorie et son set\n",
    "- rvl_cdip_draft1.csv, pour récupérer : format, width, height, mode, nb_pages, nettete, bruit_grain, ratio_b, ratio_n\n",
    "- rvl_cdip_draft_2.csv, pour récupérer : bloc, motif, num_lines, num_words, digit_ratio, top_margin, bottom_margin, left_margin, right_margin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "865794ee-0a4a-400c-83a1-81fd4ef57ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "import os\n",
    "import matplotlib.cm as cm\n",
    "from scipy.stats import gaussian_kde\n",
    "from matplotlib.lines import Line2D\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "import ast\n",
    "import cv2\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "import umap\n",
    "\n",
    "#################################### A MODIFIER SELON SA PROPRE ARBORESCENCE\n",
    "project_path = 'D:/Projet/mai25_bds_extraction/' \n",
    "####################################\n",
    "raw_data_path = os.path.join(project_path, 'data', 'raw')\n",
    "processed_data_path = os.path.join(project_path, 'data', 'processed')\n",
    "rvl_cdip_images_path = os.path.join(raw_data_path, 'RVL-CDIP', 'images')"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b653a3fd-ddee-46ad-aac9-346635d00006",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "################### Caractéristiques extraites : \n",
    "# récupérer la largeur\n",
    "df_ext_1=pd.read_csv(os.path.join(project_path, 'data', 'extracted','rvl_cdip_draft1.csv'))\n",
    "df_ext_1=df_ext_1.drop(columns=['Unnamed: 0','format','height','mode','nb_pages','nettete','bruit_grain','ratio_b','ratio_n'], axis=1)\n",
    "df_ext_1['relative_path'] = df_ext_1['relative_path'].str.replace('\\\\', '/', regex=False)\n",
    "df_ext_1['path'] = df_ext_1['relative_path']+'/'+df_ext_1['filename']\n",
    "\n",
    "#premières caractéristiques extraites :  nettete, bruit_grain, ratio_b, ratio_n, entropy\n",
    "df_extract  = pd.read_parquet(os.path.join(project_path, 'data', 'extracted', 'df_rvl_cdip_basic_features.parquet'))\n",
    "#les colonnes ratio_b et ratio_n ont été inversées, donc on les renomme en conséquence\n",
    "df_extract = df_extract.rename(columns={\"black_ratio\":'ratio_b', \"white_ratio\":'ratio_n', 'rvl_image_path':'path'})\n",
    "\n",
    "\n",
    "# caractéristiques supplémentaires : blocs, feature, bord, motif\n",
    "df_extract_plus = pd.read_parquet(os.path.join(project_path, 'data', 'extracted', 'df_rvl_cdip_advanced_features.parquet'))\n",
    "df_extract_plus = df_extract_plus.rename(columns={'rvl_image_path':'path'})\n",
    "\n",
    "# Comm je suis une quiche, je n'ai pas enregistré le bon path pour les images, il dépend de mon ordinateur... \n",
    "prefix = 'D:/Projet/mai25_bds_extraction/data\\\\raw/RVL-CDIP/images/' #le r permet de comprendre que les \\ et / doivent être gardées\n",
    "df_extract['path'] = df_extract['path'].str.replace(prefix, '', regex=False)\n",
    "df_extract_plus['path'] = df_extract_plus['path'].str.replace(prefix, '', regex=False)\n",
    "\n",
    "df_extract_1 = pd.merge(df_extract, df_ext_1, on='path', how='left', suffixes=('', '_ext1'))\n",
    "################### On enlève la ligne avec des Nan partout:\n",
    "df_extract_1=df_extract_1.dropna(axis=0, how='any')\n",
    "df_extract_plus=df_extract_plus.dropna(axis=0, how='any')\n",
    "\n",
    "################### train.txt, test.txt et val.txt : \n",
    "# récupération des catégories et du set dans lequel chaque image se trouve\n",
    "df_train  = pd.read_csv(os.path.join(project_path, 'data', 'raw', 'train.txt'), sep=\" \", header=None)\n",
    "df_train.columns=['path', 'cat']\n",
    "df_train['set']=['train' for i in range (len(df_train))]\n",
    "\n",
    "df_test  = pd.read_csv(os.path.join(project_path, 'data', 'raw', 'test.txt'), sep=\" \", header=None)\n",
    "df_test.columns=['path', 'cat']\n",
    "df_test['set']=['test' for i in range (len(df_test))]\n",
    "\n",
    "df_val  = pd.read_csv(os.path.join(project_path, 'data', 'raw', 'val.txt'), sep=\" \", header=None)\n",
    "df_val.columns=['path', 'cat']\n",
    "df_val['set']=['val' for i in range (len(df_val))]\n",
    "\n",
    "#on fait un dataframe intermédiaire dans lequel on stocke les données de nos 3 dataframes. \n",
    "df_inter = pd.concat([df_train, df_test, df_val])\n",
    "\n",
    "################### On assemble tous les dataframes dans un grand avec tout ce qu'on sait pour chaque image :\n",
    "df_1 = pd.merge(df_extract_1, df_inter)\n",
    "df = pd.merge(df_extract_plus, df_1)\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4ac7c315-b631-48a2-8032-cbbec27fe97a",
   "metadata": {},
   "source": [
    "df.to_parquet(os.path.join(project_path, 'data', 'extracted', \"rvl_cdip_all_extracted.parquet\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fedae50-acb9-4da0-99d6-955a77c93400",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet(os.path.join(project_path, 'data', 'extracted', 'rvl_cdip_all_extracted.parquet'))\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c51ff5db-7288-42e7-83e0-fbb3a6cf7bd5",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Exploration de chaque caractéristique extraite <a class=\"anchor\" id=\"c2\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca3108e4-9eee-468b-b3e3-402a229fcfb6",
   "metadata": {},
   "source": [
    "### Creation des fonctions nécessaires<a id=\"s2_0\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "180bb105-1f20-4e40-b9b3-5bd8282126ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chercher_extremes(col,seuil,comparaison=\"sup\"):\n",
    "    \"\"\"\n",
    "    Cette fonction permet l'affichage des images (et leur path et nom) pour lesquels un seuil est dépassé pour une colonne de df\n",
    "    col = nom de la colonne de df considérée\n",
    "    seuil = valeur du seuil\n",
    "    comparaison = \"sup\" si on veut garder les valeurs supérieures au seuil, et \"inf\" si on veut garder les valeurs inférieures\n",
    "    \"\"\"\n",
    "    if comparaison == \"inf\":\n",
    "        paths = df[df[col]<seuil]['relative_path'].to_list()\n",
    "        file = df[df[col]<seuil]['filename'].to_list()\n",
    "        cat = df[df[col]<seuil]['cat'].to_list()\n",
    "    else :\n",
    "        paths = df[df[col]>seuil]['relative_path'].to_list()\n",
    "        file = df[df[col]>seuil]['filename'].to_list()\n",
    "        cat = df[df[col]>seuil]['cat'].to_list()\n",
    "\n",
    "    # Afficher les images concernées\n",
    "    for i in range (len(paths)):\n",
    "        print(paths[i],\" : \", file[i],\", catégorie : \", cat[i])\n",
    "        file_path = os.path.join(rvl_cdip_images_path, paths[i], file[i])\n",
    "        image = cv2.imread(file_path, cv2.IMREAD_GRAYSCALE)\n",
    "        plt.imshow(image, cmap='gray')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cddc339f-a3bb-4d35-b733-b58107d0a66c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def percentile(col,mini,maxi):\n",
    "    q_min= np.percentile(df[col], mini)\n",
    "    q_max=np.percentile(df[col], maxi)\n",
    "    print(maxi-mini,\"% des données sont entre \",q_min,' et ', q_max)\n",
    "    return q_min, q_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f764227-4cfa-44f7-af0d-ab46135c4b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def histogramme(col, q5, q95):\n",
    "    # Paramètres pour l'impression\n",
    "    plt.rcParams.update({\n",
    "        'font.size': 16,          # Taille générale\n",
    "        'axes.titlesize': 20,     # Titre du graphique\n",
    "        'axes.labelsize': 18,     # Titres des axes\n",
    "        'legend.fontsize': 14,    # Taille de légende\n",
    "        'xtick.labelsize': 14,\n",
    "        'ytick.labelsize': 14\n",
    "    })\n",
    "\n",
    "    plt.figure(figsize=(12,7))\n",
    "    plt.hist(df[col], bins=60, color='#15016B')\n",
    "    plt.axvline(q5, color='#FF5733', linestyle='dashed', linewidth=2, label='5e percentile')\n",
    "    plt.axvline(q95, color='#FFC300', linestyle='dashed', linewidth=2, label='95e percentile')\n",
    "    plt.legend()\n",
    "    plt.xlabel(str(col))\n",
    "    plt.ylabel(\"Fréquence\")\n",
    "    plt.title(f\"Distribution de la colonne : {col}\")\n",
    "    plt.show()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b97b04c-03d3-4896-ad31-730dfdcc7af7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9b7f83dc-bb2f-466d-807a-83997a99a93c",
   "metadata": {},
   "source": [
    "### Largeur <a id=\"s2_1\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4700c4ec-f896-4530-9da7-44119c44f3e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "q5_w, q95_w = percentile('width',5,95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f19f0dcb-c8af-414e-9a91-292c3b27e7b2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# On fait un histogramme en échelle log pour y voir  clair\n",
    "plt.figure(figsize=(12,7))\n",
    "plt.rcParams.update({\n",
    "        'font.size': 16,          # Taille générale\n",
    "        'axes.titlesize': 20,     # Titre du graphique\n",
    "        'axes.labelsize': 18,     # Titres des axes\n",
    "        'legend.fontsize': 14,    # Taille de légende\n",
    "        'xtick.labelsize': 14,\n",
    "        'ytick.labelsize': 14\n",
    "    })\n",
    "plt.hist(df['width'], bins=300, log=True, color='#15016B')\n",
    "plt.axvline(q5_w, color='#FF5733', linestyle='dashed', linewidth=2, label='5e percentile')\n",
    "plt.axvline(q95_w, color='#FFC300', linestyle='dashed', linewidth=2, label='95e percentile')\n",
    "plt.legend()\n",
    "plt.xlabel(\"Largeur\")\n",
    "plt.ylabel(\"Fréquence (échelle log)\")\n",
    "plt.title(\"Distribution des largeurs (échelle logarithmique)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0344544-9fe9-476e-8868-84af2e323723",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# images avec une très grande largeur\n",
    "chercher_extremes('width',2500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12e15062-fe36-4a9f-90ca-2c056c0f0e75",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# images avec la plus petite largeur\n",
    "chercher_extremes('width',600,comparaison=\"inf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49b82b9f-757d-4160-9716-8efc0a7c1d71",
   "metadata": {},
   "source": [
    "### Netteté <a id=\"s2_2\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c406c56e-b5ce-43ee-a57f-d6f166e3a6d4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "q5_n, q95_n = percentile('sharpness',5,95)\n",
    "histogramme('sharpness', q5_n, q95_n)\n",
    "\n",
    "print('###############################')\n",
    "\n",
    "# images avec la plus basse netteté\n",
    "chercher_extremes('sharpness',0.00005,comparaison=\"inf\")\n",
    "\n",
    "print('###############################')\n",
    "\n",
    "# images avec la plus grande netteté\n",
    "chercher_extremes('sharpness',0.017,comparaison=\"sup\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45b66806-a72a-4cf7-a3b4-b8f91185b025",
   "metadata": {},
   "source": [
    "### Bruit <a id=\"s2_3\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8d96fd6-3330-4972-b843-9f8d5d393566",
   "metadata": {},
   "outputs": [],
   "source": [
    "q5_b, q95_b = percentile('noise',5,95)\n",
    "histogramme('noise', q5_b, q95_b)\n",
    "\n",
    "print('###############################')\n",
    "\n",
    "# images avec le plus faible bruit\n",
    "chercher_extremes('noise',1.2,comparaison=\"inf\")\n",
    "\n",
    "print('###############################')\n",
    "\n",
    "# images avec le plus fort bruit\n",
    "chercher_extremes('noise',59,comparaison=\"sup\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aec6f98f-9466-430c-8191-32afdc52f1ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Voyons les images avec peu de bruit\n",
    "# Filtrer les lignes où le bruit est inférieur à 0.05 pour aller regarder à quoi correspondent ces images\n",
    "b_paths = df[df['bruit_grain']<0.05]['relative_path'].to_list()\n",
    "b_file = df[df['bruit_grain']<0.05]['filename'].to_list()\n",
    "b_cat = df[df['bruit_grain']<0.05]['cat'].to_list()\n",
    "\n",
    "# Afficher les chemins relatifs concernés\n",
    "for i in range (len(b_paths)):\n",
    "    print(b_paths[i],\" : \", b_file[i],\" : \", b_cat[i])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1683a2b4-9817-44f0-bd0b-40c9f312284e",
   "metadata": {},
   "source": [
    "### Ratio pixels blancs / total <a id=\"s2_4\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "101eb715-ac4a-4be6-a1de-92c1f1fb5110",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "q5_rb, q95_rb = percentile('ratio_b',5,95)\n",
    "histogramme('ratio_b', q5_rb, q95_rb)\n",
    "\n",
    "print('###############################')\n",
    "\n",
    "# images avec le plus ratio de blanc\n",
    "chercher_extremes('ratio_b',0.03,comparaison=\"inf\")\n",
    "\n",
    "print('###############################')\n",
    "\n",
    "# images avec le plus fort ratio de blanc\n",
    "chercher_extremes('ratio_b',0.9995,comparaison=\"sup\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3be3ecca-5ea2-42b3-9557-eadc86f59470",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "151b475c-09b2-4569-920f-e9c604d9bc1c",
   "metadata": {},
   "source": [
    "### Ratio pixels noirs / total <a id=\"s2_5\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05ea995a-4a92-473d-8c98-3455495786e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "q5_rn, q95_rn = percentile('ratio_n',5,95)\n",
    "histogramme('ratio_n', q5_rn, q95_rn)\n",
    "\n",
    "print('###############################')\n",
    "\n",
    "# images avec le plus petit ratio de noir\n",
    "chercher_extremes('ratio_n',0.00003,comparaison=\"inf\")\n",
    "\n",
    "print('###############################')\n",
    "\n",
    "# images avec le plus fort ratio de noir\n",
    "chercher_extremes('ratio_n',0.97,comparaison=\"sup\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7474bf45-83ba-4e61-b34b-578f8bb85347",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6101a4ac-cf84-4a0b-a53f-cd551bb5ef6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "fig.add_trace(go.Histogram(x=df_extract['ratio_b'], name=\"ratio pixels blancs\", marker_color='rgb(255,195,0)'))\n",
    "fig.add_trace(go.Histogram(x=df_extract['ratio_n'], name=\"ratio pixels noirs\", marker_color='rgb(21, 1, 107)'))\n",
    "\n",
    "# Change the bar mode\n",
    "fig.update_layout(\n",
    "    #barmode='overlay'\n",
    "    title=dict(text=\"Histogramme des ratios du nombre de pixels blancs sur le nombre total de pixels\"),\n",
    "    xaxis=dict(title=dict(text=\"Ratio\"), \n",
    "               tickmode='linear',  # Mode linéaire\n",
    "               dtick=0.05             # Un tick toutes les 1 unité\n",
    "              ),\n",
    "    yaxis=dict(title=dict(text=\"Nombre de documents\")),\n",
    "    legend=dict(title=dict(text=\"ratios\"))\n",
    ")\n",
    "fig.update_traces(opacity=0.75)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9c7cbdd-2783-41ae-a67e-4a1f14715afa",
   "metadata": {},
   "source": [
    "### Entropie <a id=\"s2_6\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78c1f48c-4be4-41f4-a7fb-246fd35e5f0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d652d66-5281-453a-96cc-8bc58884e052",
   "metadata": {},
   "outputs": [],
   "source": [
    "q5_e, q95_e = percentile('entropy',5,95)\n",
    "histogramme('entropy', q5_e, q95_e)\n",
    "\n",
    "print('###############################')\n",
    "\n",
    "# images avec le plus petit ratio de noir\n",
    "chercher_extremes('entropy',0.008,comparaison=\"inf\")\n",
    "\n",
    "print('###############################')\n",
    "\n",
    "# images avec le plus fort ratio de noir\n",
    "chercher_extremes('entropy',5.3,comparaison=\"sup\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78bfa286-de2f-4dec-bbd6-b88fd2c41f2e",
   "metadata": {},
   "source": [
    "### Nombre de lignes <a id=\"s2_7\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "382141fb-7f64-4ba8-a785-10afe3b1c5a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "q5_nl, q95_nl = percentile('nb_lignes',5,95)\n",
    "histogramme('nb_lignes', q5_nl, q95_nl)\n",
    "\n",
    "print('###############################')\n",
    "\n",
    "# images avec le plus petit ratio de noir\n",
    "chercher_extremes('nb_lignes',0.008,comparaison=\"inf\")\n",
    "\n",
    "print('###############################')\n",
    "\n",
    "# images avec le plus fort ratio de noir\n",
    "chercher_extremes('nb_lignes',95,comparaison=\"sup\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "118773a8-7001-4d82-a7a0-7e3578c01fa4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fd490728-badd-4c85-945d-9a06b5a89247",
   "metadata": {},
   "source": [
    "### Nombre de colonnes <a id=\"s2_8\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18422758-815a-4050-b71e-97db458d5221",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "q5_nc, q95_nc = percentile('nb_colonnes',5,95)\n",
    "histogramme('nb_colonnes', q5_nc, q95_nc)\n",
    "\n",
    "print('###############################')\n",
    "\n",
    "# images avec le plus petit ratio de noir\n",
    "#chercher_extremes('nb_colonnes',0,comparaison=\"inf\")\n",
    "\n",
    "print('###############################')\n",
    "\n",
    "# images avec le plus fort ratio de noir\n",
    "chercher_extremes('nb_colonnes',6,comparaison=\"sup\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "511f8934-fc76-4c82-989b-369f1719a820",
   "metadata": {},
   "source": [
    "### Marges <a id=\"s2_9\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f356e091-8596-4039-a3da-6d5792dbc3f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e2499db-cc89-4a51-bdc9-fd04a3d10a98",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "q5_tm, q95_tm = percentile('top_marge',5,95)\n",
    "histogramme('top_marge', q5_tm, q95_tm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "169308d2-afd2-48db-be89-91825edd59c2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "q5_bm, q95_bm = percentile('bottom_marge',5,95)\n",
    "histogramme('bottom_marge', q5_bm, q95_bm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cebd0de3-43c7-4d9a-a703-1deca9e9a8b0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "q5_rm, q95_rm = percentile('right_marge',5,95)\n",
    "histogramme('right_marge', q5_rm, q95_rm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a6b75a7-3949-46cc-9770-a92fa4552be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "q5_lm, q95_lm = percentile('left_marge',5,95)\n",
    "histogramme('left_marge', q5_lm, q95_lm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1d74b21-4493-460e-960f-3ed2565b32a9",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Répartitions dans les différents sets <a id=\"c3\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3449aeb8-9a7b-4a57-91f2-d9a73d475e3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def repart(col):\n",
    "    df['bins']=pd.cut(df[col], \n",
    "                        bins=[0, \n",
    "                             np.quantile(df[col], 0.1),\n",
    "                             np.quantile(df[col], 0.2), #en fait, Q1, Q2, Q3, Q4 et Q5 ont la même valeur...\n",
    "                             np.quantile(df[col], 0.3),\n",
    "                             np.quantile(df[col], 0.4),\n",
    "                             np.quantile(df[col], 0.5),\n",
    "                             np.quantile(df[col], 0.6),\n",
    "                             np.quantile(df[col], 0.7),\n",
    "                             np.quantile(df[col], 0.8),\n",
    "                             np.quantile(df[col], 0.9),\n",
    "                             df[col].max()], \n",
    "                        labels=['min-Q1', 'Q1-Q2', 'Q2-Q3', 'Q3-Q4', 'Q4-Q5', 'Q5-Q6', 'Q6-Q7', 'Q7-Q8', 'Q8-Q9', 'Q9-max'],\n",
    "                        include_lowest=True)\n",
    "\n",
    "    # On compte les fichiers par classe et set\n",
    "    df_counts = df.groupby(['bins', 'set']).size().reset_index(name='count')\n",
    "\n",
    "    # On calcule la proportion pour chaque classe\n",
    "    set_order = ['train', 'test', 'val']\n",
    "    class_order = ['min-Q1', 'Q1-Q2', 'Q2-Q3', 'Q3-Q4', 'Q4-Q5', 'Q5-Q6', 'Q6-Q7', 'Q7-Q8', 'Q8-Q9', 'Q9-max']\n",
    "    df_counts['set'] = pd.Categorical(df_counts['set'], categories=set_order, ordered=True)\n",
    "    df_counts['proportion'] = df_counts.groupby('bins')['count'].transform(lambda x: x / x.sum())\n",
    "\n",
    "    # Graphique en barres empilées, proportions normalisées\n",
    "    fig = px.bar(\n",
    "        df_counts,\n",
    "        x='bins',\n",
    "        y='proportion',\n",
    "        color='set',\n",
    "        category_orders={'bins': class_order, 'set': set_order},\n",
    "        title=\"Répartition des fichiers par classe, par set, selon : \"+col,\n",
    "        labels={'proportion': 'Proportion', 'bins': 'Classe'},\n",
    "        color_discrete_sequence=['rgb(87, 24, 69)', 'rgb(199, 0, 57)', 'rgb(255,87,51)']\n",
    "    )\n",
    "\n",
    "    fig.update_layout(barmode='stack', yaxis=dict(tickformat=\".0%\", title=\"Proportion\"),\n",
    "                     width=600, height=500)\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "987c1695-22f4-48a3-a3af-2d96896f6e02",
   "metadata": {},
   "source": [
    "### On regarde la répartition des images dans les différents dataframes selon leurs caractéristiques\n",
    "\n",
    "Pour cela, on va commencer par faire des 'bins' pour nos variables d'intérêt, et pour chaque bin, regarder si son contenu est correctement réparti dans les 3 datasets (en proportion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fee1085-c575-42f4-9e3f-d5b356e5e852",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['width_bins']=pd.cut(df['width'], \n",
    "                        bins=[0, \n",
    "                             np.quantile(df['width'], 0.1)-1,\n",
    "                             #np.quantile(df['width'], 0.2), #en fait, Q1, Q2, Q3, Q4 et Q5 ont la même valeur...\n",
    "                             #np.quantile(df['width'], 0.3),\n",
    "                             #np.quantile(df['width'], 0.4),\n",
    "                             np.quantile(df['width'], 0.5),\n",
    "                             np.quantile(df['width'], 0.6),\n",
    "                             np.quantile(df['width'], 0.7),\n",
    "                             #np.quantile(df['width'], 0.8),\n",
    "                             np.quantile(df['width'], 0.9),\n",
    "                             df['width'].max()], \n",
    "                        labels=['min-Q1', 'Q1-Q5', 'Q5-Q6', 'Q6-Q7', 'Q7-Q9', 'Q9-max'],\n",
    "                        include_lowest=True)\n",
    "\n",
    "# On compte les fichiers par classe et set\n",
    "df_counts = df.groupby(['width_bins', 'set']).size().reset_index(name='count')\n",
    "\n",
    "# On calcule la proportion pour chaque classe\n",
    "set_order = ['train', 'test', 'val']\n",
    "class_order = ['min-Q1', 'Q1-Q5', 'Q5-Q6', 'Q6-Q7', 'Q7-Q9', 'Q9-max']\n",
    "df_counts['set'] = pd.Categorical(df_counts['set'], categories=set_order, ordered=True)\n",
    "df_counts['proportion'] = df_counts.groupby('width_bins')['count'].transform(lambda x: x / x.sum())\n",
    "\n",
    "# Graphique en barres empilées, proportions normalisées\n",
    "fig = px.bar(\n",
    "    df_counts,\n",
    "    x='width_bins',\n",
    "    y='proportion',\n",
    "    color='set',\n",
    "    category_orders={'classe': class_order, 'set': set_order},\n",
    "    title='Répartition des fichiers par classe de largeur et par set',\n",
    "    labels={'proportion': 'Proportion', 'width_bins': 'Classe'},\n",
    "    color_discrete_sequence=['rgb(87, 24, 69)', 'rgb(199, 0, 57)', 'rgb(255,87,51)']\n",
    ")\n",
    "\n",
    "fig.update_layout(barmode='stack', yaxis=dict(tickformat=\".0%\", title=\"Proportion\"),width=600, height=500)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78f29f01-954b-464f-b4e1-ceb9748fb493",
   "metadata": {},
   "outputs": [],
   "source": [
    "repart('sharpness')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44d4ac06-127e-4bd4-a931-ae98e76bf0d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "repart('noise')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62899d7e-e5ef-4a49-aeb3-6a14f434361b",
   "metadata": {},
   "outputs": [],
   "source": [
    "repart('ratio_b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11eddbf9-129e-48e6-af21-d7e98e902c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "repart('ratio_n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b371f215-46a9-4e71-ba27-358afbfc258b",
   "metadata": {},
   "outputs": [],
   "source": [
    "repart('entropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cc81e7f-1704-4fb2-9c0b-7e8fa0a645f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "repart('nb_lignes')"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d7cc557f-8b35-401e-9473-85cca841d44b",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "001303e6-bf55-4a86-886e-ffb7f5c0f5f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['nb_colonnes_bins']=pd.cut(df['nb_colonnes'], \n",
    "                        bins=[0, 1, 2, 3, 4, 5, df['nb_colonnes'].max()], \n",
    "                        labels=['0 ou 1', '2', '3', '4', '5', '>5'],\n",
    "                        include_lowest=True)\n",
    "\n",
    "# On compte les fichiers par classe et set\n",
    "df_counts = df.groupby(['nb_colonnes_bins', 'set']).size().reset_index(name='count')\n",
    "\n",
    "# On calcule la proportion pour chaque classe\n",
    "set_order = ['train', 'test', 'val']\n",
    "class_order = ['0', '1', '2', '3', '4', '5', '>5']\n",
    "df_counts['set'] = pd.Categorical(df_counts['set'], categories=set_order, ordered=True)\n",
    "df_counts['proportion'] = df_counts.groupby('nb_colonnes_bins')['count'].transform(lambda x: x / x.sum())\n",
    "\n",
    "# Graphique en barres empilées, proportions normalisées\n",
    "fig = px.bar(\n",
    "    df_counts,\n",
    "    x='nb_colonnes_bins',\n",
    "    y='proportion',\n",
    "    color='set',\n",
    "    category_orders={'ratio_b_bins': class_order, 'set': set_order},\n",
    "    title='Répartition des fichiers par set selon : nb_colonnes',\n",
    "    labels={'proportion': 'Proportion', 'ratio_b_bins': 'Classe'},\n",
    "    color_discrete_sequence=['rgb(87, 24, 69)', 'rgb(199, 0, 57)', 'rgb(255,87,51)']\n",
    ")\n",
    "\n",
    "fig.update_layout(barmode='stack', yaxis=dict(tickformat=\".0%\", title=\"Proportion\"), width=500, height=500)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aa84111-d1b0-42ef-9c59-531baa9c445e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Corrélation entre les caractéristiques <a class=\"anchor\" id=\"c4\"></a>\n",
    "\n",
    "- pour voir si la prédiction des catégories avec nos caractéristiques est possible\n",
    "- pour voir si nos caractéristiques extraites ne sont pas trop redondantes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a624e6f1-347c-4ea0-89a6-debf9a6a2376",
   "metadata": {},
   "source": [
    "### Heatmap des corrélations <a class=\"anchor\" id=\"c4_1\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9081ff79-7fd3-4fb0-a6b2-24a1307acca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "611f3604-1c0a-4acd-8202-dac11ec83b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# corrélations entre les caractéristiques extraites:\n",
    "\n",
    "plt.figure(figsize=(12, 10))\n",
    "fig = go.Figure(data=go.Heatmap(\n",
    "                    z=df[['top_marge', 'bottom_marge', 'left_marge', 'right_marge', 'nb_lignes', 'nb_colonnes', 'sharpness', 'noise', 'ratio_b', 'ratio_n', 'entropy']].corr(),\n",
    "                    x=['top_marge', 'bottom_marge', 'left_marge', 'right_marge', 'nb_lignes', 'nb_colonnes', 'sharpness', 'noise', 'ratio_b', 'ratio_n', 'entropy'],\n",
    "                    y=['top_marge', 'bottom_marge', 'left_marge', 'right_marge', 'nb_lignes', 'nb_colonnes', 'sharpness', 'noise', 'ratio_b', 'ratio_n', 'entropy'],\n",
    "                    text=round(df[['top_marge', 'bottom_marge', 'left_marge', 'right_marge', 'nb_lignes', 'nb_colonnes', 'sharpness', 'noise', 'ratio_b', 'ratio_n', 'entropy']].corr(),2),\n",
    "                    texttemplate=\"%{text}\",\n",
    "                    colorscale ='RdBu'))\n",
    "\n",
    "fig.update_layout(title=dict(text=\"Corrélation des caractéristiques extraites\"))\n",
    "fig.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a0cc7ab-62ac-44f2-b304-ab9c6f87e21d",
   "metadata": {},
   "source": [
    "### Scatter plots et courbes de densité <a class=\"anchor\" id=\"c4_2\"></a>\n",
    "on ne peut pas inclure les catégories dans l'heatmap donc on va déjà regarder ce que ça donne avec des nuages de poinrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c2873b8-230f-48c8-8268-7389480df7da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def densite_90(col1, col2):\n",
    "    \n",
    "    # Paramètres pour l'impression\n",
    "    plt.rcParams.update({\n",
    "        'font.size': 14,          # Taille générale\n",
    "        'axes.titlesize': 18,     # Titre du graphique\n",
    "        'axes.labelsize': 16,     # Titres des axes\n",
    "        'legend.fontsize': 12,    # Taille de légende\n",
    "        'xtick.labelsize': 12,\n",
    "        'ytick.labelsize': 12\n",
    "    })\n",
    "    \n",
    "    # Sous-échantillonnage\n",
    "    max_points = 5000\n",
    "    df_reduced = df.groupby('cat').apply(lambda x: x.sample(min(len(x), max_points), random_state=42)).reset_index(drop=True)\n",
    "    \n",
    "    # Couleurs\n",
    "    categories = sorted(df_reduced['cat'].unique())\n",
    "    cmap = cm.get_cmap('rainbow', len(categories))\n",
    "    cat_colors = {cat: cmap(i) for i, cat in enumerate(categories)}\n",
    "    \n",
    "    # Déterminer dynamiquement la grille pour la densité\n",
    "    x_min, x_max = df_reduced[col1].min(), df_reduced[col1].max()\n",
    "    y_min, y_max = df_reduced[col2].min(), df_reduced[col2].max()\n",
    "    \n",
    "    # Ajouter un léger padding (5%) pour éviter les bordures trop serrées\n",
    "    x_pad = (x_max - x_min) * 0.05\n",
    "    y_pad = (y_max - y_min) * 0.05\n",
    "\n",
    "    x_grid = np.linspace(x_min - x_pad, x_max + x_pad, 100)\n",
    "    y_grid = np.linspace(y_min - y_pad, y_max + y_pad, 100)\n",
    "    X, Y = np.meshgrid(x_grid, y_grid)\n",
    "    positions = np.vstack([X.ravel(), Y.ravel()])\n",
    "    \n",
    "    # Figure adaptée à une page A4 paysage (~11.7 x 8.3 pouces)\n",
    "    fig = plt.figure(figsize=(11.7, 8.3))  # taille A4 paysage en pouces\n",
    "    \n",
    "    # Tracer les contours\n",
    "    for cat in categories:\n",
    "        sub_df = df_reduced[df_reduced['cat'] == cat]\n",
    "        x = sub_df[col1].values\n",
    "        y = sub_df[col2].values\n",
    "    \n",
    "        if len(x) < 10:\n",
    "            continue\n",
    "    \n",
    "        values = np.vstack([x, y])\n",
    "        kde = gaussian_kde(values)\n",
    "        Z = np.reshape(kde(positions).T, X.shape)\n",
    "    \n",
    "        z_vals = kde(values)\n",
    "        threshold = np.percentile(z_vals, 10)\n",
    "    \n",
    "        plt.contour(\n",
    "            X, Y, Z,\n",
    "            levels=[threshold],\n",
    "            colors=[cat_colors[cat]],\n",
    "            alpha=0.6,\n",
    "            linewidths=2.5\n",
    "        )\n",
    "    \n",
    "    # Légende propre\n",
    "    legend_elements = [Line2D([0], [0], color=cat_colors[cat], lw=3, label=f'Catégorie {cat}') for cat in categories]\n",
    "    plt.legend(\n",
    "        handles=legend_elements,\n",
    "        title=\"Catégories\",\n",
    "        loc='center left',\n",
    "        bbox_to_anchor=(1.05, 0.5),\n",
    "        frameon=True\n",
    "    )\n",
    "    # Mise en forme finale\n",
    "    plt.title(\"Zones principales de densité par catégorie\", pad=20)\n",
    "    plt.xlabel(col1)\n",
    "    plt.ylabel(col2)\n",
    "    plt.xlim(x_min - x_pad, x_max + x_pad)\n",
    "    plt.ylim(y_min - y_pad, y_max + y_pad)\n",
    "    plt.grid(True, linestyle='--', alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Optionnel : sauvegarde en HD pour rapport\n",
    "    # plt.savefig(\"densite_categories_A4.png\", dpi=300)  # ou .pdf\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f456919-5800-46fd-b132-9f127a4ddaec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "\n",
    "# Liste des colonnes à combiner\n",
    "cols = ['top_marge', 'bottom_marge', 'left_marge', 'right_marge',\n",
    "        'nb_lignes', 'nb_colonnes', 'sharpness', 'noise',\n",
    "        'ratio_b', 'ratio_n', 'entropy', 'width']\n",
    "\n",
    "# Boucle sur toutes les paires uniques (sans ordre)\n",
    "for col1, col2 in combinations(cols, 2):\n",
    "    print(f\"Graphique : {col1} vs {col2}\")\n",
    "    densite_90(col1, col2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ea9743c-0da4-4efb-a16f-91d3193f9b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "densite_90('bottom_marge','nb_lignes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3842ee50-0425-462e-9d23-7370f777a804",
   "metadata": {},
   "outputs": [],
   "source": [
    "densite_90('bottom_marge','entropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef8ab4e7-c18b-46e3-9231-17b996916750",
   "metadata": {},
   "outputs": [],
   "source": [
    "densite_90('left_marge','nb_lignes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0dda547-87ca-4dc2-a43c-47f02f75d768",
   "metadata": {},
   "outputs": [],
   "source": [
    "densite_90('nb_lignes','noise')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8df4454f-a398-4fa7-9a86-85f92c428f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "densite_90('sharpness','noise')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76b3bc04-ba4d-417e-a882-d78c7a9235b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "densite_90('sharpness','entropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "493fd0e3-2858-4227-9515-d9a050ee9274",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#j'ai voulu le faire avec plotly pour avoir le hover mais du coup ça garde en tête des infos et c'est très très lourd et ça fait freezer le notebook\n",
    "plt.figure(figsize=(15,10))\n",
    "plt.scatter(x=df[df['width']<1500]['width'], \n",
    "            y=df[df['width']<1500]['bruit_grain'], \n",
    "            c=df[df['width']<1500]['cat'],\n",
    "            s=2\n",
    "           )\n",
    "plt.colorbar()\n",
    "plt.title(\"Catégories (en couleur) selon la largeur et le bruit\")\n",
    "plt.xlabel(\"Largeur (<1500)\")\n",
    "plt.ylabel(\"Bruit/grain\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61f870e6-a504-4a07-a7da-9a343f016d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Une palette de couleurs fixes\n",
    "import matplotlib.cm as cm\n",
    "categories = sorted(df['cat'].unique())\n",
    "cmap = cm.get_cmap('rainbow', len(categories))  # nombre de couleurs = nombre de catégories\n",
    "cat_colors = {cat: cmap(i) for i, cat in enumerate(categories)}\n",
    "\n",
    "# Boucle sur chaque catégorie unique\n",
    "for cat in categories:\n",
    "    sub_df = df[df['cat'] == cat]\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.scatter(\n",
    "        x=sub_df['ratio_n'], \n",
    "        y=sub_df['bruit_grain'], \n",
    "        color=cat_colors[cat],\n",
    "        label=f'Catégorie {cat}',\n",
    "        s=2\n",
    "    )\n",
    "    plt.legend(title=\"Catégories\")\n",
    "    plt.title(f\"Catégorie {cat} - largeur vs ratio de pixels noirs\")\n",
    "    plt.xlabel(\"Ratio de pixels noirs\")\n",
    "    plt.ylabel(\"Bruit/grain\")\n",
    "    plt.xlim([0, 1])\n",
    "    plt.ylim([0, 60])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eafd96c-7400-4c34-898b-5e42e171523c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aa0ac35-e48a-4b44-9f47-f3ed1f1b55d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ea1edf48-a1d5-4e72-ad68-8f3cafbdc0a1",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## LDA <a class=\"anchor\" id=\"c5\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38c4fa64-12ad-4aa6-9c08-1964a6db119f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38be9d5e-17b6-4d35-9c18-914442474a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f859545-1e10-4ebb-9d9e-f13d5b259b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Variables numériques\n",
    "features = ['top_marge', 'bottom_marge', 'left_marge',\n",
    "       'right_marge', 'nb_lignes', 'nb_colonnes', 'sharpness', 'noise',\n",
    "       'ratio_b', 'ratio_n', 'entropy', 'width']\n",
    "X = df[features].values\n",
    "y = df['cat'].values\n",
    "\n",
    "# Appliquer LDA\n",
    "lda = LinearDiscriminantAnalysis(n_components=2)\n",
    "X_lda = lda.fit_transform(X, y)\n",
    "\n",
    "# Génération de couleurs fixes\n",
    "import matplotlib.cm as cm\n",
    "categories = sorted(np.unique(y))\n",
    "cmap = cm.get_cmap('rainbow', len(categories))\n",
    "cat_colors = {cat: cmap(i) for i, cat in enumerate(categories)}\n",
    "\n",
    "# Plot 2D\n",
    "plt.figure(figsize=(12, 8))\n",
    "for cat in categories:\n",
    "    idx = (y == cat)\n",
    "    plt.scatter(X_lda[idx, 0], X_lda[idx, 1], \n",
    "                color=cat_colors[cat], \n",
    "                s=5, alpha=0.6, \n",
    "                label=f'Catégorie {cat}')\n",
    "\n",
    "plt.xlabel(\"LD1 (axe le plus discriminant)\")\n",
    "plt.ylabel(\"LD2 (deuxième axe)\")\n",
    "plt.title(\"Projection LDA des catégories (5 variables → 2D)\")\n",
    "plt.legend(title=\"Catégories\", markerscale=2, fontsize=\"small\", loc='best')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8bc1aa5-2b60-45ef-bebb-79790ee3e8fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#On refait la même mais avec les courbes de niveau à 90% pour une meilleure lisibilité \n",
    "\n",
    "# Variables numériques\n",
    "features = ['top_marge', 'bottom_marge', 'left_marge',\n",
    "       'right_marge', 'nb_lignes', 'nb_colonnes', 'sharpness', 'noise',\n",
    "       'ratio_b', 'ratio_n', 'entropy', 'width']\n",
    "X = df[features].values\n",
    "y = df['cat'].values\n",
    "\n",
    "# Appliquer LDA\n",
    "lda = LinearDiscriminantAnalysis(n_components=2)\n",
    "X_lda = lda.fit_transform(X, y)\n",
    "\n",
    "# Génération de couleurs fixes\n",
    "import matplotlib.cm as cm\n",
    "categories = sorted(np.unique(y))\n",
    "cmap = cm.get_cmap('rainbow', len(categories))\n",
    "cat_colors = {cat: cmap(i) for i, cat in enumerate(categories)}\n",
    "\n",
    "# Préparer la figure\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Pour chaque catégorie\n",
    "for cat in categories:\n",
    "    idx = (y == cat)\n",
    "    data = X_lda[idx].T  # shape (2, N)\n",
    "    \n",
    "    # Estimation de densité\n",
    "    kde = gaussian_kde(data)\n",
    "    \n",
    "    # Créer une grille sur laquelle évaluer la densité\n",
    "    xmin, xmax = X_lda[:, 0].min(), X_lda[:, 0].max()\n",
    "    ymin, ymax = X_lda[:, 1].min(), X_lda[:, 1].max()\n",
    "    xx, yy = np.mgrid[xmin:xmax:200j, ymin:ymax:200j]\n",
    "    grid = np.vstack([xx.ravel(), yy.ravel()])\n",
    "    zz = kde(grid).reshape(xx.shape)\n",
    "\n",
    "    # Déterminer le niveau correspondant à 90% de la densité cumulée\n",
    "    levels = np.linspace(zz.min(), zz.max(), 100)\n",
    "    zz_sorted = np.sort(zz.ravel())[::-1]\n",
    "    cumsum = np.cumsum(zz_sorted)\n",
    "    cumsum /= cumsum[-1]\n",
    "    level90 = zz_sorted[np.searchsorted(cumsum, 0.90)]\n",
    "\n",
    "    # Tracer la courbe de niveau à 90%\n",
    "    plt.contour(xx, yy, zz, levels=[level90],\n",
    "                colors=[cat_colors[cat]],\n",
    "                linewidths=2, alpha=0.5,\n",
    "                label=f'Catégorie {cat}')\n",
    "\n",
    "# Légende et titres\n",
    "plt.xlabel(\"LD1 (axe le plus discriminant)\")\n",
    "plt.ylabel(\"LD2 (deuxième axe)\")\n",
    "plt.title(\"Courbes de niveau (90%) LDA par catégorie\")\n",
    "plt.legend(title=\"Catégories\", fontsize=\"small\", loc='best')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "052b907c-7a35-4d52-9f25-1dd77e26d3f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02863a3b-bcd0-4fb5-b6cb-d606debb1ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#On refait la même mais avec un robust scaler\n",
    "\n",
    "# Variables numériques\n",
    "features = ['top_marge', 'bottom_marge', 'left_marge',\n",
    "       'right_marge', 'nb_lignes', 'nb_colonnes', 'sharpness', 'noise',\n",
    "       'ratio_b', 'ratio_n', 'entropy', 'width']\n",
    "X = df[features].values\n",
    "y = df['cat'].values\n",
    "scaler = RobustScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Appliquer LDA\n",
    "lda = LinearDiscriminantAnalysis(n_components=2)\n",
    "X_lda = lda.fit_transform(X_scaled, y)\n",
    "\n",
    "# Génération de couleurs fixes\n",
    "import matplotlib.cm as cm\n",
    "categories = sorted(np.unique(y))\n",
    "cmap = cm.get_cmap('rainbow', len(categories))\n",
    "cat_colors = {cat: cmap(i) for i, cat in enumerate(categories)}\n",
    "\n",
    "# Préparer la figure\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Pour chaque catégorie\n",
    "for cat in categories:\n",
    "    idx = (y == cat)\n",
    "    data = X_lda[idx].T  # shape (2, N)\n",
    "    \n",
    "    # Estimation de densité\n",
    "    kde = gaussian_kde(data)\n",
    "    \n",
    "    # Créer une grille sur laquelle évaluer la densité\n",
    "    xmin, xmax = X_lda[:, 0].min(), X_lda[:, 0].max()\n",
    "    ymin, ymax = X_lda[:, 1].min(), X_lda[:, 1].max()\n",
    "    xx, yy = np.mgrid[xmin:xmax:200j, ymin:ymax:200j]\n",
    "    grid = np.vstack([xx.ravel(), yy.ravel()])\n",
    "    zz = kde(grid).reshape(xx.shape)\n",
    "\n",
    "    # Déterminer le niveau correspondant à 90% de la densité cumulée\n",
    "    levels = np.linspace(zz.min(), zz.max(), 100)\n",
    "    zz_sorted = np.sort(zz.ravel())[::-1]\n",
    "    cumsum = np.cumsum(zz_sorted)\n",
    "    cumsum /= cumsum[-1]\n",
    "    level90 = zz_sorted[np.searchsorted(cumsum, 0.90)]\n",
    "\n",
    "    # Tracer la courbe de niveau à 90%\n",
    "    plt.contour(xx, yy, zz, levels=[level90],\n",
    "                colors=[cat_colors[cat]],\n",
    "                linewidths=2, alpha=0.5,\n",
    "                label=f'Catégorie {cat}')\n",
    "\n",
    "# Légende et titres\n",
    "plt.xlabel(\"LD1 (axe le plus discriminant)\")\n",
    "plt.ylabel(\"LD2 (deuxième axe)\")\n",
    "plt.title(\"Courbes de niveau (90%) LDA par catégorie\")\n",
    "plt.legend(title=\"Catégories\", fontsize=\"small\", loc='best')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1445626e-2618-4966-9ff1-9f553b2410e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# essai avec UMAP\n",
    "\n",
    "import umap\n",
    "reducer = umap.UMAP(n_neighbors=30, min_dist=0.1)\n",
    "X_umap = reducer.fit_transform(X_scaled)\n",
    "\n",
    "# Réducteur UMAP\n",
    "reducer = umap.UMAP(n_components=2, n_neighbors=30, min_dist=0.1, random_state=42)\n",
    "\n",
    "# Transformation\n",
    "X_umap = reducer.fit_transform(X_scaled)\n",
    "\n",
    "# Création DataFrame pour faciliter la visualisation\n",
    "df_umap = pd.DataFrame(X_umap, columns=['UMAP1', 'UMAP2'])\n",
    "df_umap['cat'] = y  # ajouter les catégories\n",
    "\n",
    "# Génération de couleurs fixes\n",
    "import matplotlib.cm as cm\n",
    "categories = sorted(np.unique(y))\n",
    "cmap = cm.get_cmap('rainbow', len(categories))\n",
    "cat_colors = {cat: cmap(i) for i, cat in enumerate(categories)}\n",
    "\n",
    "# Préparer la figure\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Pour chaque catégorie\n",
    "for cat in categories:\n",
    "    idx = (y == cat)\n",
    "    data = X_umap[idx].T  # shape (2, N)\n",
    "    \n",
    "    # Estimation de densité\n",
    "    kde = gaussian_kde(data)\n",
    "    \n",
    "    # Créer une grille sur laquelle évaluer la densité\n",
    "    xmin, xmax = X_umap[:, 0].min(), X_umap[:, 0].max()\n",
    "    ymin, ymax = X_umap[:, 1].min(), X_umap[:, 1].max()\n",
    "    xx, yy = np.mgrid[xmin:xmax:200j, ymin:ymax:200j]\n",
    "    grid = np.vstack([xx.ravel(), yy.ravel()])\n",
    "    zz = kde(grid).reshape(xx.shape)\n",
    "\n",
    "    # Déterminer le niveau correspondant à 90% de la densité cumulée\n",
    "    levels = np.linspace(zz.min(), zz.max(), 100)\n",
    "    zz_sorted = np.sort(zz.ravel())[::-1]\n",
    "    cumsum = np.cumsum(zz_sorted)\n",
    "    cumsum /= cumsum[-1]\n",
    "    level90 = zz_sorted[np.searchsorted(cumsum, 0.90)]\n",
    "\n",
    "    # Tracer la courbe de niveau à 90%\n",
    "    plt.contour(xx, yy, zz, levels=[level90],\n",
    "                colors=[cat_colors[cat]],\n",
    "                linewidths=2, alpha=0.5,\n",
    "                label=f'Catégorie {cat}')\n",
    "\n",
    "# Légende et titres\n",
    "plt.xlabel(\"LD1 (axe le plus discriminant)\")\n",
    "plt.ylabel(\"LD2 (deuxième axe)\")\n",
    "plt.title(\"Courbes de niveau (90%) LDA par catégorie\")\n",
    "plt.legend(title=\"Catégories\", fontsize=\"small\", loc='best')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d95510ef-cf8c-413d-8deb-7da6ee608912",
   "metadata": {},
   "source": [
    "Wow... Qu'est ce que c'est que ça ??"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f287636-9636-49ae-a1f6-2af441b07c90",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Comparaison avec IIT <a class=\"anchor\" id=\"c5\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c187e56d-4ba7-4fc6-90a0-51cac984b92a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fichier = os.path.join(project_path, 'data', 'extracted', 'df_iit_cdip_basic_features.parquet')\n",
    "iit_1 = pd.read_parquet(fichier, engine='fastparquet')\n",
    "iit_1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1240a5c4-0768-4f70-b843-4de55761d8d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "iit_1['mode'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbe4dec1-d5e4-47c5-aef1-20807fd57b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "iit_1['mode'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "626106df-4a03-4a79-8cf8-ac8b73a8c52e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fichier = os.path.join(project_path, 'data', 'extracted', 'df_iit_cdip_basic_features_INCOMPLET.parquet')\n",
    "iit = pd.read_parquet(fichier, engine='fastparquet')\n",
    "iit.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b5ea644-47bd-405e-9b6e-1870e124a461",
   "metadata": {},
   "outputs": [],
   "source": [
    "iit[iit['sharpness']>0.08]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac4717a4-2f01-489b-beb6-6f0efb53858f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,7))\n",
    "plt.rcParams.update({\n",
    "        'font.size': 16,          # Taille générale\n",
    "        'axes.titlesize': 20,     # Titre du graphique\n",
    "        'axes.labelsize': 18,     # Titres des axes\n",
    "        'legend.fontsize': 14,    # Taille de légende\n",
    "        'xtick.labelsize': 14,\n",
    "        'ytick.labelsize': 14\n",
    "    })\n",
    "plt.hist(df['sharpness'], bins=12, color='#15016B', alpha = 0.5, label='RVL-CDIP', log=True)\n",
    "plt.hist(iit['sharpness'], bins=60, color='#900C3E', alpha = 0.5 , label='IIT-CDIP', log=True)\n",
    "plt.legend()\n",
    "plt.xlabel(\"Sharpness\")\n",
    "plt.ylabel(\"Fréquence\")\n",
    "plt.title(\"Distribution de la netteté\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9f9dfab-251f-48dd-b2d0-624e2fd5095f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,7))\n",
    "plt.rcParams.update({\n",
    "        'font.size': 16,          # Taille générale\n",
    "        'axes.titlesize': 20,     # Titre du graphique\n",
    "        'axes.labelsize': 18,     # Titres des axes\n",
    "        'legend.fontsize': 14,    # Taille de légende\n",
    "        'xtick.labelsize': 14,\n",
    "        'ytick.labelsize': 14\n",
    "    })\n",
    "plt.hist(iit['noise'], bins=60, color='#900C3E', alpha = 0.5 , label='IIT-CDIP', log=True)\n",
    "plt.hist(df['noise'], bins=60, color='#15016B', alpha = 0.5, label='RVL-CDIP', log=True)\n",
    "\n",
    "plt.legend()\n",
    "plt.xlabel(\"noise\")\n",
    "plt.ylabel(\"Fréquence\")\n",
    "plt.title(\"Distribution du bruit\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65602e7c-7fad-4297-b756-ea0a5ec513e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,7))\n",
    "plt.rcParams.update({\n",
    "        'font.size': 16,          # Taille générale\n",
    "        'axes.titlesize': 20,     # Titre du graphique\n",
    "        'axes.labelsize': 18,     # Titres des axes\n",
    "        'legend.fontsize': 14,    # Taille de légende\n",
    "        'xtick.labelsize': 14,\n",
    "        'ytick.labelsize': 14\n",
    "    })\n",
    "plt.hist(iit['entropy'], bins=10, color='#900C3E', alpha = 0.5 , label='IIT-CDIP', log=True)\n",
    "plt.hist(df['entropy'], bins=60, color='#15016B', alpha = 0.5, label='RVL-CDIP', log=True)\n",
    "\n",
    "plt.legend()\n",
    "plt.xlabel(\"entropy\")\n",
    "plt.ylabel(\"Fréquence\")\n",
    "plt.title(\"Distribution de l'entropie\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a1d8985-481a-480f-aaef-6799d79bc535",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:DL]",
   "language": "python",
   "name": "conda-env-DL-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
