{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "10d62f92-bf90-4417-bdbf-91ea85bd6356",
   "metadata": {},
   "source": [
    "# Extraction des données IIT-CDIP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e6e9ffa-4686-4392-82a9-f5dc1bfea767",
   "metadata": {},
   "source": [
    "## README\n",
    "Ce notebook permet de télécharger sur le site \"https://data.nist.gov\" les images et métadonnées de la BDD IIT-CDIP associées aux images RVL-CDIP.\n",
    "\n",
    "Il réalise tout d'abord certaines opérations préalables (chapitre 1), dont la configuration des répertoires du projet\n",
    "\n",
    "\n",
    "A l'issue (chapitre 2), il reconstitue la liste des identifiants de documents de la BDD RVL-CDIP qui se trouvent dans le répertoire *rvl_cdip_images_path*.\n",
    "\n",
    "Ensuite (chapitre 3), il identifie les images tar à télécharger (en ignorant celles qui ont déjà été pleinement exploitées), les télécharge sur le site *data.nist.gov* puis écrit sur le disque dur, dans l'arborescence du répertoire *iit_cdip_images_path*, les fichiers tif et xml concernés.\n",
    "\n",
    "Remarques:\n",
    "- Lors de cette phase, les fichiers .tar téléchargés sont volumineux (environ 2.5 GB par fichier, et environ 600 fichiers tar au total, ce qui représente plus d'1 To de données à télécharger). Toutefois, les fichiers à conserver ne réprésentent qu'un peu moins de 70Go. Pour éviter des écritures disque inutiles et l'occupation d'un très gros volume, il a été choisi de traiter les fichiers téléchargés à la volée, sans les écrire sur le disque dur. L'inconvénient est que si l'on souhaite accéder à nouveau à ce fichier tar, il faudra le télécharger à nouveau. L'avantage, au delà de l'économie d'usure des disques durs) est de limiter l'espace disque requis.\n",
    "- Dans les fichiers .tar téléchargés, certains documents ne disposent pas de fichiers xml associés. Dans ce cas, seule l'image est obtenue.\n",
    "\n",
    "Enfin (chapitre 4), le notebook permet de télécharger les fichiers xml \"collectifs\", dans lesquels sont rassemblées les métadonnées de plusieurs documents (environ 10000 par fichier). Les fichiers téléchargés sont traités à la volée pour être extraits et réduits afin de ne conserver que les métadonnées liées aux documents de la base de données RVL_CDIP. Ce traitement évite à nouveaux des accès disque et permet de faire passer le volume requis d'environ 24 Go à environ 3 Go.\n",
    "\n",
    "Remarque:\n",
    "- **[IMPORTANT] Au bilan, l'utilisation de ce script écrira environ 70 Go de fichiers tif et xml sur le disque dur et téléchargera environ 1,5 To d'internet**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "062badf2-5141-40e7-afdb-1917f5c8c7e9",
   "metadata": {},
   "source": [
    "## 1. Préparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7652e965-d7d3-4ab8-8ab6-88fa19674436",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "project_root = Path().resolve().parent\n",
    "if not project_root in [Path(p).resolve() for p in sys.path]:\n",
    "    sys.path.append(str(project_root))\n",
    "\n",
    "from src import PATHS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31f516d3-1792-4ef1-816c-2f50c5750386",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import io\n",
    "import gzip\n",
    "import time\n",
    "import requests\n",
    "import tarfile\n",
    "import pandas as pd\n",
    "from lxml import etree"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6716c0b4-b564-4833-86a9-fa970547a801",
   "metadata": {},
   "source": [
    "## 2. Création de la liste des identifiants des images RVL-CDIP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37328581-ea71-420b-a138-f975055f4baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rvl_cdip_image_ids(rvl_cdip_images_path):\n",
    "    tmp_list = []\n",
    "    for foldername, _, filenames in os.walk(rvl_cdip_images_path):\n",
    "        if filenames:\n",
    "            filename = filenames[0]\n",
    "            # we check that the structure is relevant to our expectation with 2 asserts\n",
    "            assert len(filenames) == 1, f\"{foldername},{filename}\"\n",
    "            if filename.startswith('.'): # avoid to consider files like .DS_Store on mac\n",
    "                continue\n",
    "            assert filename.endswith(\".tif\"), f\"{foldername},{filename}\"\n",
    "            tmp_list.append((os.path.basename(foldername), filename))\n",
    "    tmp_list.sort()\n",
    "    return pd.DataFrame(tmp_list, columns = [\"document_id\", \"filename\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0461ca5-1aa8-4b0a-9a6a-ff850e3f98cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = time.time()\n",
    "df = get_rvl_cdip_image_ids(PATHS.rvl_cdip_images)\n",
    "print(f\"Duree d'exécution: {time.time() - t:.3f} secondes.\")\n",
    "print(f\"({len(df)} images traitées)\\n\")\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "473d7808-47fd-4e68-90b1-af56a95d48ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[:, \"first_letter\"] = df.document_id.str.slice(stop = 1)\n",
    "df.loc[:, \"first_two_letters\"] = df.document_id.str.slice(stop = 2)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68ddf6d6-9917-411a-943b-ed7148c4b9c7",
   "metadata": {},
   "source": [
    "## 3. Téléchargement des images et fichiers xml individuels de la base IIT-CDIP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfaffa5c-f89b-4681-87bb-bd6dcd04401e",
   "metadata": {},
   "outputs": [],
   "source": [
    "groupby_images = df.groupby(\"first_two_letters\").agg(\n",
    "    {'document_id': list, 'filename': list}).rename(\n",
    "    columns={\"document_id\": \"document_ids\", \"filename\":\"filenames\"})\n",
    "groupby_images.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff34c466-d7d2-41be-ae4f-55d7dd48175f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_existing_ids(ids_list: list, filenames_list: list, iit_cdip_images_path: str, also_check_xmls = True):\n",
    "    \"\"\"From given lists of image ids and filenames, remove those for which image already exists in iit_cdip_images_path\n",
    "    Return a new list containing ids that do not exist yet.\n",
    "    \"\"\"\n",
    "    missing_ids = []\n",
    "    missing_filenames = []\n",
    "    for id_, filename in zip(ids_list, filenames_list):\n",
    "        expected_file_path = PATHS.iit_cdip_images / f\"images{id_[0]}\" / id_[0] / id_[1] / id_[2] / id_ / filename\n",
    "        # expected_file_path = \"/Users/ben/Work/mle/ds-project/mai25_bds_extraction/data_sample/raw/IIT-CDIP/images/imagesa/a/a/a/aaa0a000/92464841_4842.tif\"\n",
    "        image_exists = expected_file_path.exists()\n",
    "        \n",
    "        if also_check_xmls:\n",
    "            expected_file_path = PATHS.iit_cdip_images / f\"images{id_[0]}\" / id_[0] / id_[1] / id_[2] / id_ / f\"{id_}.xml\"\n",
    "            xml_exists = expected_file_path.exists()\n",
    "        else:\n",
    "            xml_exists = True\n",
    "        if not (image_exists and xml_exists):\n",
    "            missing_ids.append(id_)\n",
    "            missing_filenames.append(filename)\n",
    "    return missing_ids, missing_filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88cb9746-47a3-45ef-9922-a51ae1d87702",
   "metadata": {},
   "outputs": [],
   "source": [
    "nist_images_base_url = \"https://data.nist.gov/od/ds/ark:/88434/mds2-2531/cdip-images/\"\n",
    "def import_iit_cdip_images_set(letters, ids, filenames, iit_cdip_images_path, iit_cdip_xmls_path, nist_images_base_url):\n",
    "    missing_files = [\n",
    "        os.path.join(f\"images{id_[0]}\", id_[0], id_[1], id_[2], id_, filename) \n",
    "                    for id_, filename in zip(ids, filenames)] + [\n",
    "        os.path.join(f\"images{id_[0]}\", id_[0], id_[1], id_[2], id_, f\"{id_}.xml\") \n",
    "                    for id_ in ids]\n",
    "    # exemple d'url d'un dossier d'images sur NIST: \n",
    "    # https://data.nist.gov/od/ds/ark:/88434/mds2-2531/cdip-images/images.a.a.tar\n",
    "    url = f\"{nist_images_base_url}images.{letters[0]}.{letters[1]}.tar\"\n",
    "    print(\"   ... fetching \", url)\n",
    "    t = time.time()\n",
    "    tif_amount, xml_amount = 0, 0\n",
    "    reponse = requests.get(url, stream=True)\n",
    "    reponse.raise_for_status()  # En cas d'erreur HTTP\n",
    "    with tarfile.open(fileobj=io.BytesIO(reponse.content), mode=\"r|*\") as archive:\n",
    "        for file in archive:\n",
    "            if file.name in missing_files:\n",
    "                archive.extract(file, path=PATHS.iit_cdip_images)\n",
    "                if file.name.endswith('.tif'):\n",
    "                    tif_amount += 1\n",
    "                else:\n",
    "                    xml_amount += 1\n",
    "    print(f\"   ... Successfully extracted {tif_amount} tif + {xml_amount} xml files, in {time.time() - t:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2128fcd-d380-4d43-8c5e-5e135ed861dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, serie in groupby_images.iterrows():\n",
    "    letters = index\n",
    "    ids_list = serie.document_ids\n",
    "    filenames_list = serie.filenames\n",
    "    missing_ids, missing_filenames = remove_existing_ids(ids_list, filenames_list, PATHS.iit_cdip_images, also_check_xmls = False)\n",
    "    print(f\"Processing letters {letters}: {len(missing_ids)} images to retrieve\")\n",
    "    if missing_ids:\n",
    "        import_iit_cdip_images_set(letters, missing_ids, missing_filenames, PATHS.iit_cdip_images, PATHS.iit_cdip_xmls, nist_images_base_url)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f0835d1-db49-47e8-9e7a-bbd8a7c6abb8",
   "metadata": {},
   "source": [
    "## 4. Téléchargement des xmls communs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8ca4820-9a59-413a-933e-63c83df4a485",
   "metadata": {},
   "outputs": [],
   "source": [
    "# urls de téléchargement=\n",
    "# https://data.nist.gov/od/ds/ark:/88434/mds2-2531/cdip-text/cdip-1.tar\n",
    "# de 1 à 6\n",
    "\n",
    "for n in range(1, 7):\n",
    "    print(f\"Downloading  du fichier {n}/6\")\n",
    "    url = f\"https://data.nist.gov/od/ds/ark:/88434/mds2-2531/cdip-text/cdip-{n}.tar\"\n",
    "    reponse = requests.get(url, stream=True)\n",
    "    with tarfile.open(fileobj=io.BytesIO(reponse.content), mode=\"r|*\") as archive:\n",
    "        for gz_info in archive:\n",
    "            letters = gz_info.name[8] + gz_info.name[10]\n",
    "            rvl_ids = rvl_cdip_df[rvl_cdip_df.document_id.str.startswith(letters)].document_id.tolist()\n",
    "            output_filename = PATHS.iit_cdip_xmls / f\"{letters}.xml\"\n",
    "            z_file = archive.extractfile(gz_info)\n",
    "            compressed_data = z_file.read()\n",
    "            decompressed_data = gzip.decompress(compressed_data)\n",
    "            try:\n",
    "                xml_file = io.BytesIO(decompressed_data)\n",
    "                parser = etree.XMLParser(recover=True)\n",
    "                tree = etree.parse(xml_file, parser)\n",
    "                root = tree.getroot()\n",
    "            except Exception as e:\n",
    "                print(f\"Erreur de parsing XML : {e}\")\n",
    "                continue    \n",
    "            print(gz_info.name, letters, \":\", \"existing records=\", len(root.findall(\"record\")), end=\"\")\n",
    "            for record in root.findall(\"record\"):\n",
    "                docid_text = getattr(record.find(\"docid\"), \"text\", None)\n",
    "                if docid_text not in rvl_ids:\n",
    "                    root.remove(record)\n",
    "            tree.write(output_filename)\n",
    "            print(\" kept \", len(root.findall(\"record\")), \" out of \", len(rvl_ids), \" possibles.\")\n",
    "                \n",
    "                "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
