{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "96a873bd-c824-4abc-97ae-c1995e2d771c",
   "metadata": {},
   "source": [
    "# Création DataFrame IIT_CDIP_COLL_XML_FEATURES"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b2f69fa-179c-4dc8-bd79-86a87c6f4cc0",
   "metadata": {},
   "source": [
    "## README\n",
    "Ce notebook permet d'exploiter les fichiers xml collectifs associés aux images de la base de données RVL-CDIP par \"jointure\" sur la base de données IIT-CDIP. Les informations extraites sont rassemblées dans deux DataFrame, qui correspondent aux deux sources de données ayant alimenté le xml:\n",
    "- iit_cdip_coll_xml_a_features\n",
    "- iit_cdip_coll_xml_ltdlwocr_features\n",
    "La différence entre les deux sources est ainsi décrite:\n",
    "*The information in the <A> and <LTDLWOCR> elements is largely, but not completely, redundant with each other. The data in the <LTDLWOCR> elements was produced more recently and fixes some known minor glitches with data in the <A> elements.  On the other hand, some of the interesting data in the <LTDLWOCR> elements is in XML comments, while all the data in the <A> elements is in XML subelements.*\n",
    "\n",
    "Il réalise tout d'abord certaines opérations préalables (chapitre 1), dont la définition des variables globales d'exécution (**A METTRE A JOUR LORS D'UNE PREMIERE UTILISATION**)\n",
    "\n",
    "A l'issue (chapitre 2), il explore les fichiers xml afin d'en déterminer la structure. Deux dictionnaires de tags sont créés dans cette partie afin de pouvoir renommer les colonnes à terme. \n",
    "\n",
    "Enfin (chapitre 3), il permet de créer les deux DataFrame, qui contiennent les informations suivantes:\n",
    "#### iit_cdip_coll_xml_a_features\n",
    "- document_id\n",
    "- corporate_source\n",
    "- title\n",
    "- authors_people_or_org\n",
    "- corporate_source_and_id\n",
    "- document_date\n",
    "- attachment_group\n",
    "- people_org_attending\n",
    "- brands\n",
    "- bates_number\n",
    "- copied_people_org\n",
    "- legal_case_id\n",
    "- leagal_case_name\n",
    "- document_characteristics\n",
    "- document_description\n",
    "- document_begin_bates_number\n",
    "- document_end_bates_number\n",
    "- date_loaded\n",
    "- date_modified\n",
    "- date_produced\n",
    "- document_type\n",
    "- estimated_date\n",
    "- ending_date\n",
    "- file\n",
    "- grant_number\n",
    "- litigation_usage\n",
    "- names_mentionned\n",
    "- names_noted\n",
    "- oklahoma_downgrades\n",
    "- page_count\n",
    "- physical_attachment_1\n",
    "- physical_attachment_2\n",
    "- production_box\n",
    "- recipients\n",
    "- redacted\n",
    "- request_number\n",
    "- source\n",
    "- special_collections\n",
    "- date_shipped\n",
    "- source_site\n",
    "- st\n",
    "- trial_exhibit\n",
    "- topics\n",
    "#### iit_cdip_coll_xml_ltdlwocr_features\n",
    "- document_id\n",
    "- authors_people\n",
    "- bates_number\n",
    "- production_box\n",
    "- authors_organization\n",
    "- recipients\n",
    "- document_date\n",
    "- date_modified\n",
    "- document_type\n",
    "- file\n",
    "- names_mentionned_organization\n",
    "- names_mentionned_people\n",
    "- ocr_output\n",
    "- copied_people_org\n",
    "- page_count\n",
    "- recipients\n",
    "- title"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba9ac3b2-34f0-4771-864c-56431bed3dd7",
   "metadata": {},
   "source": [
    "## 1. Préparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23c09c12-24e0-4837-948c-0af4db139811",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "project_root = Path().resolve().parent\n",
    "if not project_root in [Path(p).resolve() for p in sys.path]:\n",
    "    sys.path.append(str(project_root))\n",
    "\n",
    "from src import PATHS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91d20fdd-ae3f-45b5-87b3-f5c7544e87c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "from lxml import etree\n",
    "from functools import reduce\n",
    "from utils import remove_ds_store_files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c708c844-5844-4695-b8d9-8f2f7d85d869",
   "metadata": {},
   "source": [
    "## 2. Exploration des fichiers xml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1a25284-5c23-46c9-bc64-e8ce916c33e0",
   "metadata": {},
   "source": [
    "### 2.1. Identification de la structure des fichiers xml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee98efd8-3a52-4ac3-bd44-949e1767b8be",
   "metadata": {},
   "outputs": [],
   "source": [
    "class StructureNode:\n",
    "    def __init__(self, tag_name):\n",
    "        self.tag_name = tag_name\n",
    "        self.attributes = set()\n",
    "        self.children = {}\n",
    "\n",
    "    def add_attributes(self, attrib_keys):\n",
    "        self.attributes.update(attrib_keys)\n",
    "\n",
    "    def add_child(self, child_node):\n",
    "        if not isinstance(child_node, StructureNode):\n",
    "            raise TypeError(f\"Expected StructureNode, got {type(child_node)}\")\n",
    "        if child_node.tag_name not in self.children:\n",
    "            self.children[child_node.tag_name] = child_node\n",
    "        else:\n",
    "            self.children[child_node.tag_name].merge(child_node)\n",
    "\n",
    "    def merge(self, other_node):\n",
    "        self.attributes.update(other_node.attributes)\n",
    "        for child_tag, child_node in other_node.children.items():\n",
    "            if child_tag in self.children:\n",
    "                self.children[child_tag].merge(child_node)\n",
    "            else:\n",
    "                self.children[child_tag] = child_node\n",
    "\n",
    "    def display(self, level=0):\n",
    "        indent = \"  \" * level\n",
    "        attrs = f\" [attributes: {', '.join(sorted(self.attributes))}]\" if self.attributes else \"\"\n",
    "        print(f\"{indent}- {self.tag_name}{attrs}\")\n",
    "        for child in sorted(self.children.values(), key=lambda c: str(c.tag_name)):\n",
    "            child.display(level + 1)\n",
    "\n",
    "def build_structure(element):\n",
    "    node = StructureNode(element.tag)\n",
    "    node.add_attributes(element.attrib.keys())\n",
    "    for child in element:\n",
    "        if isinstance(child, etree._Element):\n",
    "            child_node = build_structure(child)\n",
    "            node.add_child(child_node)\n",
    "    return node\n",
    "\n",
    "def parse_file(filename):\n",
    "    tree = etree.parse(filename)\n",
    "    root = tree.getroot()\n",
    "    return build_structure(root)\n",
    "\n",
    "def merge_structures(root_nodes):\n",
    "    if not root_nodes:\n",
    "        return None\n",
    "    base = root_nodes[0]\n",
    "    for node in root_nodes[1:]:\n",
    "        if node.tag_name == base.tag_name:\n",
    "            base.merge(node)\n",
    "        else:\n",
    "            merged_root = StructureNode(\"MergedRoot\")\n",
    "            merged_root.add_child(base)\n",
    "            merged_root.add_child(node)\n",
    "            base = merged_root\n",
    "    return base\n",
    "\n",
    "def parse_files(files):\n",
    "    roots = []\n",
    "    for filename in files:\n",
    "        try:\n",
    "            struct = parse_file(filename)\n",
    "            roots.append(struct)\n",
    "        except (etree.XMLSyntaxError, FileNotFoundError) as e:\n",
    "            print(f\"Error processing '{filename}': {e}\")\n",
    "    return merge_structures(roots)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a272ceb0-8a33-4529-968f-fa6e86ee9e7f",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "248ac795-4964-49ab-af8a-51e0d7c6b1e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "xml_file_paths = list(PATHS.iit_cdip_xmls.iterdir())\n",
    "merged_structure = parse_files(xml_file_paths)\n",
    "merged_structure.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae5c53ac-f35d-4147-bf11-5e3fe8dfe4d9",
   "metadata": {},
   "source": [
    "### 2.2. Définiton des tags des records\n",
    "La structure ainsi retrouvée est conforme au document de description des fichiers xmls trouvé sur le net (en l'absence de DTD officiel).\n",
    "A partir de ce documents, deux dictionnaires de tags sont créés, afin de faciliter la compréhension à la lecture de la DataFrame)\n",
    "Les champs censés être parfaitement identiques entre les deux DataFrame portent strictement le même nom après conversion par le dictionnaire."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f44e3a1-7eed-4fa5-8ac3-0951de1580cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "tags_a = {\n",
    "    'DS': 'corporate_source',\n",
    "    'K': 'title',\n",
    "    'L': 'authors_people_or_org',\n",
    "    'PV': 'corporate_source_and_id',\n",
    "    'YR': 'document_date',\n",
    "    'ag': 'attachment_group',\n",
    "    'at': 'people_org_attending',\n",
    "    'b': 'brands',\n",
    "    'br': 'bates_number',\n",
    "    'c': 'copied_people_org',\n",
    "    'ci': 'legal_case_id',\n",
    "    'cn': 'leagal_case_name',\n",
    "    'co': 'document_characteristics',\n",
    "    'd': 'document_description',\n",
    "    'db': 'document_begin_bates_number',\n",
    "    'de': 'document_end_bates_number',\n",
    "    'dl': 'date_loaded',\n",
    "    'dm': 'date_modified',\n",
    "    'dp': 'date_produced',\n",
    "    'dt': 'document_type',\n",
    "    'ed': 'estimated_date',\n",
    "    'eda': 'ending_date',\n",
    "    'f': 'file',\n",
    "    'gn': 'grant_number',\n",
    "    'lu': 'litigation_usage',\n",
    "    'm': 'names_mentionned',\n",
    "    'n': 'names_noted',\n",
    "    'od': 'oklahoma_downgrades',\n",
    "    'p': 'page_count',\n",
    "    'pa1': 'physical_attachment_1',\n",
    "    'pa2': 'physical_attachment_2',\n",
    "    'pb': 'production_box',\n",
    "    'r': 'recipients',\n",
    "    're': 'redacted',\n",
    "    'rn': 'request_number',\n",
    "    's': 'source',\n",
    "    'sc': 'special_collections',\n",
    "    'sh': 'date_shipped',\n",
    "    'si': 'source_site',\n",
    "    'st': 'st',\n",
    "    'te': 'trial_exhibit',\n",
    "    'tp': 'topics',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7483e1a9-acd2-40cd-86e5-8d909794f7d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tags_ltdlwocr = {\n",
    "    'au': 'authors_people',\n",
    "    'bt': 'bates_number',\n",
    "    'bx': 'production_box',\n",
    "    'ca': 'authors_organization',\n",
    "    'cr': 'recipients_organization',\n",
    "    'dd': 'document_date',\n",
    "    'dl': 'date_modified',\n",
    "    'dt': 'document_type',\n",
    "    'fn': 'file',\n",
    "    'no': 'names_mentionned_organization',\n",
    "    'np': 'names_mentionned_people',\n",
    "    'ot': 'ocr_output',\n",
    "    'pc': 'copied_people_org',\n",
    "    'pg': 'page_count',\n",
    "    'rc': 'recipients_people',\n",
    "    'ti': 'title',\n",
    "    'tid': 'document_id',\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba08754f-0501-4e1d-b7e5-137c1814ee77",
   "metadata": {},
   "source": [
    "## 3. Création et sauvegarde des DataFrames"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15c8700a-9d2b-492a-85e3-fbd10ea59b90",
   "metadata": {},
   "source": [
    "### 3.1. Création"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5970d7a6-ae96-4b4a-8a67-f2e1d6c36fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_records_from_file(file_path):\n",
    "    tree = etree.parse(file_path)\n",
    "    root = tree.getroot()\n",
    "    \n",
    "    records = root.findall(\".//record\")\n",
    "    \n",
    "    ltdlwocr_data = []\n",
    "    a_data = []\n",
    "\n",
    "    for record in records:\n",
    "        # Partie LTDLWOCR\n",
    "        ltdlwocr = record.find(\"LTDLWOCR\")\n",
    "        if ltdlwocr is not None:\n",
    "            ltdlwocr_row = {\n",
    "                child.tag: (child.text.strip() if child.text else \"\")\n",
    "                for child in ltdlwocr\n",
    "                if isinstance(child.tag, str)\n",
    "            }\n",
    "            ltdlwocr_data.append(ltdlwocr_row)\n",
    "\n",
    "        # Partie A sous ucsf200507\n",
    "        a = record.find(\"ucsf200507/A\")\n",
    "        if a is not None:\n",
    "            # On récupère l'attribut ID\n",
    "            document_id = a.attrib[\"ID\"].lower()\n",
    "            a_row = {\n",
    "                \"document_id\": document_id\n",
    "            }\n",
    "            # On ajoute les balises enfants\n",
    "            a_row.update({\n",
    "                child.tag: (child.text.strip() if child.text else \"\")\n",
    "                for child in a\n",
    "                if isinstance(child.tag, str)\n",
    "            })\n",
    "            a_data.append(a_row)\n",
    "    \n",
    "    return ltdlwocr_data, a_data\n",
    "\n",
    "\n",
    "def parse_multiple_files(file_paths):\n",
    "    all_ltdlwocr = []\n",
    "    all_a = []\n",
    "    for file_path in file_paths:\n",
    "        ltdlwocr_rows, a_rows = parse_records_from_file(file_path)\n",
    "        all_ltdlwocr.extend(ltdlwocr_rows)\n",
    "        all_a.extend(a_rows)\n",
    "\n",
    "    # Convert to DataFrames\n",
    "    df_ltdlwocr = pd.DataFrame(all_ltdlwocr)\n",
    "    df_a = pd.DataFrame(all_a)\n",
    "    \n",
    "    return df_ltdlwocr, df_a\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9107f27-2a03-43ce-b0cf-f41082969c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ltdlwocr, df_a = parse_multiple_files(xml_file_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbd781a4-6602-4214-835e-7af302bc5da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_a), len(df_ltdlwocr)\n",
    "# on retrouve les 2000 fichiers manquants suite au téléchargement des records (voir fin du notebook 1.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "134f9bf1-0fe4-47ab-865b-3df112463b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_a = df_a.rename(columns=tags_a).set_index(\"document_id\", drop=True)\n",
    "df_ltdlwocr = df_ltdlwocr.rename(columns=tags_ltdlwocr).set_index(\"document_id\", drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26f2c1d8-e0c4-438a-9021-0e683418264c",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df_a.head(1))\n",
    "display(df_ltdlwocr.head(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a37fd946-91d5-4c86-bdf8-e41eb02b3222",
   "metadata": {},
   "source": [
    "### 3.2. Sauvegarde des DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f3d4dcd-919e-42a1-94bf-3d4fc5c634a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_a.to_parquet(PATHS.processed_data / \"df_iit_cdip_coll_xml_a_features.parquet\")\n",
    "df_ltdlwocr.to_parquet(PATHS.processed_data / \"df_iit_cdip_coll_xml_ltdlwocr_features.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e66e945-2169-4a8f-bf9a-19a16a293d40",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
