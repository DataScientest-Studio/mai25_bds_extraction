{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cf06b663-d258-478e-9397-7332fbcb60ea",
   "metadata": {},
   "source": [
    "# Création DataFrames DOCUMENTS-SAMPLES"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "312083fe-fb50-4e4e-a9cf-2bc415ceca31",
   "metadata": {},
   "source": [
    "## README\n",
    "Ce notebook permet de générer des DataFrames composées d'un échantillon des données contenues dans la DataFrame DOCUMENTS.\n",
    "L'objectif de ces échantillons est de permettre de développer, tester ou appliquer des traitements sur une partie des données, afin de réduire les performances nécessaires, en termes de temps de calcul et d'espace disque requis notamment, afin de rendre possibles certaines opérations en dépit des ressources contraintes qui sont disponibles pour le projet.\n",
    "\n",
    "Il réalise tout d'abord certaines opérations préalables (chapitre 1), dont la configuration des répertoires du projet.\n",
    "\n",
    "A l'issue (chapitre 2), il permet de créer, pour 5 tailles prédéfinies, 5 échantillons de la DataFrame documents (25 DataFrames en tout).\n",
    "Chaque DataFrame conserve les mêmes proprtions de targets et de train/val/test que la DataFrame d'origine. Les Dataframe sont nommées ainsi: \n",
    "\n",
    "DOCUMENTS_SAMPLE_[x]K_[n], où:\n",
    "- x représente la taille de la DataFrame, en milliers de ligne prend des valeurs parmi {1, 4, 10, 40, 100};\n",
    "- n est un nombre entier entre 1 et 5, permettant d'identifier l'échantillon."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3320b29-b1f3-4ff5-b93a-6909b3d89062",
   "metadata": {},
   "source": [
    "## 1. Préparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a776928f-13e7-4ef7-a83a-d563ed4610fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "project_root = Path().resolve().parent\n",
    "if not project_root in [Path(p).resolve() for p in sys.path]:\n",
    "    sys.path.append(str(project_root))\n",
    "\n",
    "from src import PATHS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27a80f19-05e8-400a-9cfa-78c06ae1cbb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import itertools\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6529464b-9eeb-4565-b6e6-fd7b73c8cade",
   "metadata": {},
   "source": [
    "## 2. Création des DataFrames DOCUMENTS_SAMPLE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd7529cf-ac9f-4d5c-bee7-9f051211181d",
   "metadata": {},
   "source": [
    "### 2.1 Chargement et ajout d'une colonne stratifier\n",
    "On ajouter cette colonne pour pouvoir l'utiliser ensuite lors de la génération des échantillons, afin de conserver, à la fois la proportion de train/val/test et celle de target. Naturellement, la colonne sera ensuite retirée de la DataFrame échantillon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2460e3d2-e6f5-4c13-95a9-1bb3f40255bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet(PATHS.metadata / \"df_data_sets.parquet\").\\\n",
    "    join(pd.read_parquet(PATHS.metadata / \"df_encoded_labels.parquet\"))\n",
    "df['stratifier'] = df.data_set + '/' + df.label.astype(str)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fe32f10-6190-4156-831b-c3129a3bc4d4",
   "metadata": {},
   "source": [
    "### 2.2 Création et sauvegarde des échantillons "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4958ecc-3df8-430d-ae8b-88c62c05b44e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sizes_k = [1, 4, 10, 40, 100]\n",
    "identifiers = list(range(1, 6))\n",
    "\n",
    "for random_state, (size, identifier) in enumerate(itertools.product(sizes_k, identifiers)):\n",
    "    sample_name = f\"df_documents_sample_{size}k_{identifier}.parquet\"\n",
    "    sample, _ = train_test_split(df, stratify=df.stratifier, train_size= 1000 * size, random_state=random_state)\n",
    "    sample[[]].to_parquet(PATHS.samples / sample_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6371c99-1697-4483-b329-684983aeb2d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verification\n",
    "# df = pd.read_parquet(os.path.join(extracted_data_path, \"df_documents_sample_100k_5.parquet\"))\n",
    "# print(df.data_set.value_counts())\n",
    "# print(df.label.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33edb8cf-bfe9-459c-bc39-e762c7ce9a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_parquet(os.path.join(PATHS.samples / \"df_documents_sample_1k_3.parquet\")).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "912feb23-a305-41f7-bbc5-ec3a4afd5736",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
