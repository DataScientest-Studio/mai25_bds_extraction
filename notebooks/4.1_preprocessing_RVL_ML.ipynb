{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b44f2640-f7c4-476f-af1f-1023cb4c1e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image, UnidentifiedImageError\n",
    "from PIL.TiffTags import TAGS\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from joblib import Parallel, delayed\n",
    "import gc\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c4d12175-1e58-4f3b-a327-9a5a0bdacd5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "project_root = Path().resolve().parent\n",
    "if not project_root in [Path(p).resolve() for p in sys.path]:\n",
    "    sys.path.append(str(project_root))\n",
    "\n",
    "from src import PATHS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9dfb849-d0f4-49b8-b443-a483d31cec26",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = PATHS.data / pd.read_parquet(PATHS.metadata / \"df_filepaths.parquet\")[[\"rvl_image_path\"]]\n",
    "df.rename(columns = {\"rvl_image_path\": \"input_path\"}, inplace=True)\n",
    "df[\"output_path\"] = PATHS.processed_data / \"ML_images_100x100\" / df[\"input_path\"].apply(lambda x: x.relative_to(PATHS.rvl_cdip_images))\n",
    "df[\"output_dir\"] = df[\"output_path\"].apply(lambda x:x.parent)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d398d11-5e54-47aa-b708-3c16c2720bea",
   "metadata": {},
   "source": [
    "## 1. Retrait des marges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34ba2e0b-0d97-4baa-9595-0e99dac38bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def marges(img):\n",
    "    \"\"\"\n",
    "    Détecte les marges haut, bas, gauche, droite d'une image TIFF en mode L.\n",
    "\n",
    "    Params:\n",
    "        image_path (str): chemin vers l'image .tiff\n",
    "    Returns:\n",
    "        top, bottom, left, right: tailles des marges en pixels\n",
    "    \"\"\"\n",
    "    # 1. récupérer l'image\n",
    "    img_np = np.array(img)\n",
    "    height, width = img_np.shape\n",
    "    \n",
    "    # Filtre médian pour réduire le bruit ponctuel\n",
    "    denoised = cv2.medianBlur(img_np, ksize=5)  # ksize impair, typiquement 3 ou 5\n",
    "\n",
    "    # Floutage gaussien pour lisser avant seuillage\n",
    "    blurred = cv2.GaussianBlur(denoised, (5, 5), 0)\n",
    "\n",
    "    # Binarisation adaptative sur image débruitée\n",
    "    binary = cv2.adaptiveThreshold(\n",
    "        blurred, 255,\n",
    "        cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
    "        cv2.THRESH_BINARY_INV,\n",
    "        blockSize=25,\n",
    "        C=15\n",
    "    )\n",
    "    \n",
    "    # 4. Projections\n",
    "    rows_sum = binary.sum(axis=1)\n",
    "    cols_sum = binary.sum(axis=0)\n",
    "    # Filtrer les lignes à analyser\n",
    "    top_bottom_ignore = 30\n",
    "    side_ignore=50 \n",
    "    # On enlève les bords parce qu'il peut y avoir des traits noirs dus à un scan de mauvaise qualité\n",
    "    valid_rows = rows_sum[top_bottom_ignore:height - top_bottom_ignore]\n",
    "    valid_cols = cols_sum[side_ignore:width - side_ignore]\n",
    "\n",
    "    if valid_rows.max() == 0 or valid_cols.max() == 0:\n",
    "        # Aucun texte détecté\n",
    "        return 0, height, 0, width\n",
    "\n",
    "    # Marges haut/bas (avec décalage)\n",
    "    top = np.argmax(valid_rows > 0) + top_bottom_ignore\n",
    "    bottom = height - top_bottom_ignore - np.argmax(valid_rows[::-1] > 0)\n",
    "\n",
    "    # Marges gauche/droite (avec décalage)\n",
    "    left = np.argmax(valid_cols > 0) + side_ignore\n",
    "    right = width - side_ignore - np.argmax(valid_cols[::-1] > 0)\n",
    "\n",
    "    return top, bottom,  left, right"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d239b8e7-0fe4-4523-940c-fcd770b1fe2a",
   "metadata": {},
   "source": [
    "## 2. resize 100 x 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "209cb7ac-4b16-454b-b1a7-4c1922064121",
   "metadata": {},
   "outputs": [],
   "source": [
    "# en fait, pas besoin d'une fonction vu qu'elle existe déjà x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e732b5be-77ca-43ac-bda4-02ebe5a9b4ec",
   "metadata": {},
   "source": [
    "## 3. Test sur 1 image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00c7e954-993d-4521-b6d9-f98b402ff5db",
   "metadata": {},
   "outputs": [],
   "source": [
    "#juste pour la visualisation\n",
    "\n",
    "def add_black_border(image, border_size=1):\n",
    "    return cv2.copyMakeBorder(\n",
    "        image,\n",
    "        top=border_size,\n",
    "        bottom=border_size,\n",
    "        left=border_size,\n",
    "        right=border_size,\n",
    "        borderType=cv2.BORDER_CONSTANT,\n",
    "        value=0  # 0 pour noir (mode grayscale)\n",
    "    )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80c42085-6934-4713-ae90-075d1aa26e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. on récupère l'image\n",
    "file_path = df.iloc[5,:][\"rvl_image_path\"]\n",
    "img = cv2.imread(file_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "# 2. Détection des marges et recadrage\n",
    "top, bottom, left, right = marges(img) \n",
    "cropped = img[top:bottom, left:right]\n",
    "\n",
    "# 3. resize\n",
    "img_resized = cv2.resize(cropped, (100, 100))\n",
    "\n",
    "# 4 : Redimensionner proportionnellement\n",
    "h, w = cropped.shape\n",
    "if h > w:\n",
    "    new_h = 100\n",
    "    new_w = int(w * 100 / h)\n",
    "else:\n",
    "    new_w = 100\n",
    "    new_h = int(h * 100 / w)\n",
    "resized = cv2.resize(cropped, (new_w, new_h))\n",
    "\n",
    "# 5 Créer un fond blanc 100x100\n",
    "canvas = np.full((100, 100), 255, dtype=np.uint8)\n",
    "\n",
    "# 6 : Coller au centre\n",
    "y_offset = 0  # image collée en haut\n",
    "x_offset = (100 - new_w) // 2  # centrage horizontal\n",
    "canvas[y_offset:y_offset+new_h, x_offset:x_offset+new_w] = resized\n",
    "\n",
    "#on rajoute une forbude pour mieux visualiser les bords\n",
    "canvas_b = add_black_border(canvas)\n",
    "img_b = add_black_border(img)\n",
    "\n",
    "# Affichage\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 6))\n",
    "\n",
    "axes[0].imshow(img_b, cmap='gray', vmin=0, vmax=255)\n",
    "axes[0].set_title(\"Image originale\")\n",
    "axes[0].axis('off')\n",
    "\n",
    "axes[1].imshow(canvas_b, cmap='gray', vmin=0, vmax=255)\n",
    "axes[1].set_title(\"Image padded avec liseret noir\")\n",
    "axes[1].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "003d703e-3b13-4b9b-bbfa-9fcf2d169123",
   "metadata": {},
   "source": [
    "## 4. Application sur l'ensemble des RVL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c069806-b09b-42e2-8a61-b434b1691838",
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_image(row):\n",
    "    input_path = row[\"input_path\"]\n",
    "    output_dir = row[\"output_dir\"]\n",
    "    output_path = row[\"output_path\"]\n",
    "\n",
    "    try:\n",
    "        img = cv2.imread(input_path, cv2.IMREAD_GRAYSCALE)\n",
    "        if img is None:\n",
    "            return f\"Erreur lecture: {input_path}\"\n",
    "\n",
    "        top, bottom, left, right = marges(img)\n",
    "        cropped = img[top:bottom, left:right]\n",
    "        img_resized = cv2.resize(cropped, (100, 100))\n",
    "\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        cv2.imwrite(output_path, img_resized)\n",
    "\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        return f\"Erreur traitement {input_path}: {e}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf918866-82f8-4b6d-81ca-e6951391b75a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_image(row):\n",
    "    input_path = row[\"input_path\"]\n",
    "    output_dir = row[\"output_dir\"]\n",
    "    output_path = row[\"output_path\"]\n",
    "\n",
    "    try:\n",
    "        img = cv2.imread(input_path, cv2.IMREAD_GRAYSCALE)\n",
    "        if img is None:\n",
    "            return f\"Erreur lecture: {input_path}\"\n",
    "\n",
    "        # Étape 1 : Rogner\n",
    "        top, bottom, left, right = marges(img)\n",
    "        cropped = img[top:bottom, left:right]\n",
    "\n",
    "        # Étape 2 : Redimensionner proportionnellement\n",
    "        h, w = cropped.shape\n",
    "        if h > w:\n",
    "            new_h = 100\n",
    "            new_w = int(w * 100 / h)\n",
    "        else:\n",
    "            new_w = 100\n",
    "            new_h = int(h * 100 / w)\n",
    "        resized = cv2.resize(cropped, (new_w, new_h))\n",
    "\n",
    "        # Étape 3 : Créer un fond blanc 100x100\n",
    "        canvas = np.full((100, 100), 255, dtype=np.uint8)\n",
    "\n",
    "        # Étape 4 : Coller au centre\n",
    "        y_offset = 0  # image collée en haut\n",
    "        x_offset = (100 - new_w) // 2  # centrage horizontal\n",
    "        canvas[y_offset:y_offset+new_h, x_offset:x_offset+new_w] = resized\n",
    "\n",
    "        # Sauvegarde\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        cv2.imwrite(output_path, canvas)\n",
    "\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        return f\"Erreur traitement {input_path}: {e}\"\n",
    "\n",
    "def parallelisation(df, n_jobs=5):\n",
    "    \n",
    "    data = df.to_dict(\"records\")\n",
    "    results = Parallel(n_jobs=n_jobs, backend='loky')(\n",
    "        delayed(new_image)(row) for row in data\n",
    "    )\n",
    "\n",
    "    erreurs = [r for r in results if r is not None]\n",
    "    if erreurs:\n",
    "        print(f\"{len(erreurs)} erreurs rencontrées :\")\n",
    "        for e in erreurs[:10]:  # aperçu\n",
    "            print(e)\n",
    "    return erreurs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c297c100-d99b-43bb-8a35-df70a512b500",
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = time.time()\n",
    "parallelisation(df, n_jobs=5)\n",
    "print(f\"Durée d'exécution: {time.time() - t0:.2f} secondes pour {len(df)} images\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e4065ce-4a56-441d-9952-6e59db373a24",
   "metadata": {},
   "source": [
    "## 5. Creation du DataFrame de 10 000 colonnes (1 ligne = 1 image, 1 colonne = 1 pixel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dab1c50-4d18-4b15-baae-fa541621b4ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def images_to_pixel_dataframe(df, include_labels=False, label_column=None):\n",
    "    records = []\n",
    "    failed = []\n",
    "    indices=[]\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        path = row[\"output_path\"]\n",
    "        try:\n",
    "            img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "            if img is None:\n",
    "                failed.append(path)\n",
    "                continue\n",
    "            flat = img.flatten().astype(np.uint8)  # moins de RAM\n",
    "            if include_labels and label_column in row:\n",
    "                flat = np.append(flat, row[label_column])\n",
    "            records.append(flat)\n",
    "            indices.append(index)\n",
    "        except Exception as e:\n",
    "            failed.append(path)\n",
    "\n",
    "    n_pixels = 100 * 100\n",
    "    col_names = [f'p_{i}' for i in range(n_pixels)]\n",
    "    if include_labels:\n",
    "        col_names.append(label_column)\n",
    "\n",
    "    df_pixels = pd.DataFrame(records, columns=col_names, index=indices)\n",
    "\n",
    "    return df_pixels, failed\n",
    "\n",
    "\n",
    "# ===============================\n",
    "#  Traitement par batch\n",
    "# ===============================\n",
    "def process_in_batches(df, batch_size, label_column=None):\n",
    "    output_dir = PATHS.processed_data / \"ML_images_100x100\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    total_batches = len(df) // batch_size + int(len(df) % batch_size != 0)\n",
    "    all_failed = []\n",
    "\n",
    "    for i in range(total_batches):\n",
    "        t0 = time.time()\n",
    "        df_batch = df.iloc[i * batch_size:(i + 1) * batch_size].copy()\n",
    "        print(f\" Batch {i+1}/{total_batches} - {len(df_batch)} images\")\n",
    "\n",
    "        # Traitement du batch\n",
    "        df_pixels, failed = images_to_pixel_dataframe(df_batch, include_labels=label_column is not None, label_column=label_column)\n",
    "        all_failed.extend(failed)\n",
    "\n",
    "        # Sauvegarde du parquet\n",
    "        batch_file = output_dir / f\"df_pixels_batch_{i:04d}.parquet\"\n",
    "        df_pixels.to_parquet(batch_file)\n",
    "        print(f\" Batch {i+1} terminé en {time.time() - t0:.2f} sec - {len(df_pixels)} images traitées\")\n",
    "\n",
    "        # Nettoyage mémoire\n",
    "        del df_batch, df_pixels\n",
    "        gc.collect()\n",
    "\n",
    "    # Sauvegarde des erreurs\n",
    "    with open(os.path.join(output_dir, \"erreurs_log.txt\"), \"w\") as f:\n",
    "        for path in all_failed:\n",
    "            f.write(path + \"\\n\")\n",
    "\n",
    "    print(f\"! Total erreurs: {len(all_failed)}\")\n",
    "\n",
    "# ===============================\n",
    "#  Concaténation finale\n",
    "# ===============================\n",
    "def concat_all_batches():\n",
    "    output_dir = PATHS.processed_data / \"ML_images_100x100\"\n",
    "    parquet_files = sorted([\n",
    "        os.path.join(output_dir, f) for f in os.listdir(output_dir)\n",
    "        if f.startswith(\"df_pixels_batch_\") and f.endswith(\".parquet\")\n",
    "    ])\n",
    "\n",
    "    print(f\" Concaténation de {len(parquet_files)} fichiers...\")\n",
    "    df_all = pd.concat([pd.read_parquet(f) for f in parquet_files])\n",
    "    df_all.to_parquet(PATHS.processed_data / \"df_pixels.parquet\")\n",
    "    print(f\" Fichier final sauvegardé: df_pixels.parquet ({len(df_all)} images)\")\n",
    "\n",
    "# ===============================\n",
    "#  Exécution\n",
    "# ===============================\n",
    "if __name__ == \"__main__\":\n",
    "    # Test sur un petit échantillon (ex: 100 images)\n",
    "    #df_test = df.sample(n=100, random_state=42).copy()\n",
    "    #process_in_batches(df_test, batch_size=20, processed_data_path=processed_data_path, label_column=None)\n",
    "    #concat_all_batches(processed_data_path)\n",
    "    \n",
    "    # Suppose que `df` et `processed_data_path` sont déjà définis\n",
    "    batch_size = 5000  # Ajuste si tu veux moins\n",
    "    process_in_batches(df, batch_size, label_column=None)\n",
    "    concat_all_batches()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3154d528-d82b-4cde-87f3-afa7e62276d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "concat_all_batches(PATHS.processed_data)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5b1115d4-598e-4a27-931a-354dcab540ba",
   "metadata": {},
   "source": [
    "def images_to_pixel_dataframe(df, include_labels=False, label_column=None):\n",
    "    records = []\n",
    "    failed = []\n",
    "    file_paths = []\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        path = row[\"output_path\"]\n",
    "        try:\n",
    "            img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "            if img is None:\n",
    "                failed.append(path)\n",
    "                continue\n",
    "            flat = img.flatten()\n",
    "            if include_labels and label_column in row:\n",
    "                flat = np.append(flat, row[label_column])\n",
    "            records.append(flat)\n",
    "            file_paths.append(str(row[\"input_path\"]))\n",
    "        except Exception as e:\n",
    "            print(f\"Erreur avec {path}: {e}\")\n",
    "            failed.append(path)\n",
    "\n",
    "    n_pixels = 100 * 100\n",
    "    col_names = [f'p_{i}' for i in range(n_pixels)]\n",
    "    if include_labels:\n",
    "        col_names.append(label_column)\n",
    "\n",
    "    df_pixels = pd.DataFrame(records, columns=col_names)\n",
    "    df_pixels[\"file_path\"] = file_paths\n",
    "\n",
    "    return df_pixels, failed"
   ]
  },
  {
   "cell_type": "raw",
   "id": "1d6f3941-1362-4bbe-85e4-ac2fe57c9afb",
   "metadata": {},
   "source": [
    "# Sélection de 100 lignes aléatoires\n",
    "#df_sample = df.sample(n=1000, random_state=42)  # random_state pour reproductibilité\n",
    "t0 = time.time()\n",
    "\n",
    "# Création du DataFrame des pixels\n",
    "df_pixels, erreurs = images_to_pixel_dataframe(df)\n",
    "df_pixels.to_parquet(PATHS.processed_data / \"ML_images_100x100\" / \"df_pixels.parquet\")\n",
    "print(f\"Durée d'exécution: {time.time() - t0:.2f} secondes pour {len(df)} images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f3d54a6-2f1d-4564-bd82-28013ba82c60",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cc2747ca-738d-489b-b657-c6990cb3ba9b",
   "metadata": {},
   "source": [
    "## 6. Completion du fichier avec fonction simple pour les données manquantes\n",
    "A permis la mmise à jour de certaines fonctions. Ne devrait plus être utile maintenant"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f7589b1-647c-43da-a3a3-7942c2e3a140",
   "metadata": {},
   "source": [
    "### 6.1 Identification des données manquantes    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18a1f5c5-f079-46de-870e-9244a749bb7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "created = pd.read_parquet(PATHS.processed_data / \"df_pixels.parquet\")\n",
    "len(created)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e358d029-8a09-4335-941b-94f2bc3842f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_missing = df[~df.index.isin(created.index)]\n",
    "df_missing.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54cac738-9879-4b9f-ab9d-57eaba9ed745",
   "metadata": {},
   "source": [
    "### 6.2 Calcul des pixels manquants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ac3c0cc-d074-4b5d-a86b-d46a487a326f",
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = []\n",
    "records = []\n",
    "for index, row in df_missing.iterrows():\n",
    "\n",
    "    input_path = row['input_path']\n",
    "    output_path = row['output_path']\n",
    "    output_dir = row['output_dir']\n",
    "    img = cv2.imread(input_path, cv2.IMREAD_GRAYSCALE)\n",
    "    if img is None:\n",
    "        print(f\"Erreur lecture: {input_path}\")\n",
    "    top, bottom, left, right = marges(img)\n",
    "    cropped = img[top:bottom, left:right]\n",
    "    img_resized = cv2.resize(cropped, (100, 100))\n",
    "    flat = img_resized.flatten().astype(np.uint8)  # moins de RAM\n",
    "    records.append(flat)\n",
    "    indices.append(index)\n",
    "\n",
    "n_pixels = 100 * 100\n",
    "col_names = [f'p_{i}' for i in range(n_pixels)]\n",
    "df_missing_pixels = pd.DataFrame(records, columns=col_names, index=indices)\n",
    "\n",
    "df_missing_pixels.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f180ab61-595c-47ea-9371-5a234f3bd688",
   "metadata": {},
   "source": [
    "### 6.3 Ajout à la df pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e3dd622-3e39-432c-be4a-c6daeb7682d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat((created, df_missing_pixels)).sort_index().to_parquet(PATHS.processed_data / \"df_pixels.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "377e495c-2bda-499b-9e4a-43d80b3059a1",
   "metadata": {},
   "source": [
    "## 7. Concatenation avec les features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fd372a70-8538-48ee-9b7d-21b00fb3c65a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pixels = pd.read_parquet(PATHS.processed_data / \"df_pixels.parquet\")\n",
    "features = pd.read_parquet(PATHS.processed_data / \"df_img_features.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "76cd329b-af82-4639-9aed-b3819ce33846",
   "metadata": {},
   "outputs": [],
   "source": [
    "features.drop(columns=['Compression'], inplace=True) # trop peu de variation\n",
    "features = features[[\n",
    "    'top_marge', 'bottom_marge', 'left_marge', 'right_marge', 'nb_lignes',\n",
    "    'nb_colonnes', 'Nettete', 'Bruit', 'Ratio_b', 'Ratio_n', 'Entropie',\n",
    "    'width']].rename(columns = {\n",
    "    'top_marge': 'top_marge',\n",
    "    'bottom_marge': 'bottom_marge',\n",
    "    'left_marge': 'left_marge',\n",
    "    'right_marge': 'right_marge',\n",
    "    'nb_lignes': 'nb_lignes',\n",
    "    'nb_colonnes': 'nb_colonnes',\n",
    "    'Nettete': 'sharpness',\n",
    "    'Bruit': 'noise',\n",
    "    'Ratio_b': 'ratio_b',\n",
    "    'Ratio_n': 'ratio_n',\n",
    "    'Entropie': 'entropy',\n",
    "    'width': 'width'\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1e4fdaff-401b-40eb-8c0b-9a55aee6e9b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_features_pixels = features.join(pixels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "50fb2b0d-dd97-4988-aee3-febf7b535de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_features_pixels.to_parquet(PATHS.processed_data / \"df_img_features_pixels.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2884a1a-686c-45cc-8fee-d8f21325b81d",
   "metadata": {},
   "source": [
    "## 8. Suppression des fichiers temporaires"
   ]
  },
  {
   "cell_type": "raw",
   "id": "235352e2-be02-452e-88ef-4b4d9b97cb8d",
   "metadata": {},
   "source": [
    "# Suppression de tous les fichiers temporaires\n",
    "# Réactiver la cellule pour utiliser\n",
    "# ATTENTION: ACTION IRREVERSIBLE\n",
    "\n",
    "for path in [\n",
    "    PATHS.processed_data / \"df_img_features.parquet\",\n",
    "    PATHS.processed_data / \"df_pixels.parquet\"\n",
    "]:\n",
    "    if path.exists():\n",
    "        path.unlink()\n",
    "        print(str(path), \"supprimé.\")\n",
    "\n",
    "import shutil\n",
    "path = PATHS.processed_data / \"ML_images_100x100\"\n",
    "if path.exists():\n",
    "    shutil.rmtree(str(path))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66a834f5-dc8f-4df5-ab31-025b0145220f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
