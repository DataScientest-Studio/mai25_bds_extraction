{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a0a84f7f-71ef-49d6-9993-2e18d6f016c6",
   "metadata": {},
   "source": [
    "# Modèles multimodaux - Voting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6abf6b4-8fec-440c-a7f1-33ac254319e2",
   "metadata": {},
   "source": [
    "## README\n",
    "Ce notebook permet la création et l'évaluation de modèles de voting.\n",
    "\n",
    "Il réalise tout d'abord certaines opérations préalables (chapitre 1)\n",
    "\n",
    "Le chapitre 2 crée et évalue un modèle de voting simple, par moyennage des prédictions de 2 modèles (1 images et 1 texte)\n",
    "\n",
    "Le chapitre 3 propose une version avancée, avec pondérations, apprises ou non, des résultats des deux modèles utilisés"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d2671d2-6c40-47d2-b044-d1011cfdbd54",
   "metadata": {},
   "source": [
    "## 1. Préparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5da9a69b-bef6-4d16-bd29-ed9c8f074f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "project_root = Path().resolve().parent\n",
    "if not project_root in [Path(p).resolve() for p in sys.path]:\n",
    "    sys.path.append(str(project_root))\n",
    "\n",
    "from src import PATHS, LABELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4ec9d71-5eca-472d-84fe-924c40100acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import pickle\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "from src.visualization.visualize import visual_classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbd19944-0cbf-47e0-8ae6-61053099be62",
   "metadata": {},
   "source": [
    "## 2. Chargement des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23eb4c85-57b6-40af-ab93-02210642d303",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = pd.read_parquet(PATHS.metadata / \"df_data_sets.parquet\")\n",
    "data_sets = pd.read_parquet(PATHS.metadata / \"df_data_sets.parquet\")\n",
    "labels = pd.read_parquet(PATHS.metadata / \"df_encoded_labels.parquet\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "1f9029e9-c084-4bc6-875f-63459f3520e9",
   "metadata": {},
   "source": [
    "# pour ne travailler que sur un échantillon\n",
    "sample = pd.read_parquet(os.path.join(PATHS.metadata, 'samples', 'df_documents_sample_40k_2.parquet'))\n",
    "documents = sample.join(documents)\n",
    "labels = sample.join(labels)\n",
    "data_sets = sample.join(data_sets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79f65ef1-1be3-48a2-97f3-2e182c26dbb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents.shape, data_sets.shape, labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c67ebb5-d49d-43ff-9c8e-808807053786",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = documents[data_sets.data_set == \"train\"].index\n",
    "y_train = labels[data_sets.data_set == \"train\"].label\n",
    "\n",
    "X_val = documents[data_sets.data_set == \"val\"].index\n",
    "y_val = labels[data_sets.data_set == \"val\"].label\n",
    "\n",
    "X_test = documents[data_sets.data_set == \"test\"].index\n",
    "y_test = labels[data_sets.data_set == \"test\"].label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cf86ee0-3fec-423b-984b-dfb4b949aedb",
   "metadata": {},
   "outputs": [],
   "source": [
    "del documents, data_sets, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a50ae38d-9ba1-4c1f-acfb-660683fc0e33",
   "metadata": {},
   "source": [
    "## 3. Chargement des modèles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d55f9417-fd58-4f5e-8589-ef22dc65985e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models.model_wrappers import ModelWrapperFactory, AGG_FN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0062d1af-c371-4b05-8655-1d85533d6e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ModelWrapperFactory.get_registered()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb64f540-eba8-4c84-add0-f3ec2ccb6f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "txt_model = ModelWrapperFactory.load_existing('Text-based Logistic Regressor')\n",
    "img_model = ModelWrapperFactory.load_existing('Image-based LGBM')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01a9960a-6cb1-4167-9949-cfece12b20b0",
   "metadata": {},
   "source": [
    "## 5. Voting simple"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a504ce29-6188-41ad-84e8-d9ca0bbf6101",
   "metadata": {},
   "source": [
    "### 5.1. Averaging "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93d47e70-c2b1-4b48-b1db-cc3f14b9e2bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "multimodal_voter = ModelWrapperFactory.make_mmo_voter_wrapper(\n",
    "    name=\"Averaging Voter\",\n",
    "    model_wrappers=[txt_model, img_model],\n",
    "    agg_fn=AGG_FN.AVERAGE\n",
    ")\n",
    "multimodal_voter.visual_report()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09f543d6-47e4-441d-b60f-da1c7436abe0",
   "metadata": {},
   "source": [
    "### 5.2. Max value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2051c5d-9ae7-4889-afbc-09cb5f599efe",
   "metadata": {},
   "outputs": [],
   "source": [
    "multimodal_voter = ModelWrapperFactory.make_mmo_voter_wrapper(\n",
    "    name=\"Max Voter\",\n",
    "    model_wrappers=[txt_model, img_model],\n",
    "    agg_fn=AGG_FN.MAX\n",
    ")\n",
    "multimodal_voter.visual_report()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ff6b396-193e-44a5-a193-6f747afc0089",
   "metadata": {},
   "source": [
    "### 5.3. Weighted\n",
    "Nous allons utiliser le jeu de validation pour déterminer la meilleure répartition des poids entre les modèles image et texte."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a919deff-747e-4c2f-bec5-d1bd1709136b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "accuracies = []\n",
    "for alpha in tqdm(np.linspace(0,1, 101)):\n",
    "    multimodal_voter = ModelWrapperFactory.make_mmo_voter_wrapper(\n",
    "        name=\"Weighted Voter\",\n",
    "        model_wrappers=[txt_model, img_model],\n",
    "        agg_fn=AGG_FN.WEIGHTED,\n",
    "        weights = [alpha, 1-alpha]\n",
    "    )\n",
    "    accuracies.append([alpha, accuracy_score(y_val, multimodal_voter.predict(X_val))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a7d499a-d88e-43dd-b26f-200e5d90bc47",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,8))\n",
    "plt.plot((0,0.49),(0.8421, 0.846), 'r--', lw=1)\n",
    "plt.plot((0.49,0.49),(0.55, 0.846), 'r--', lw=1)\n",
    "plt.plot(\n",
    "    tuple(r[0] for r in accuracies),\n",
    "    tuple(r[1] for r in accuracies)\n",
    ")\n",
    "\n",
    "plt.xticks(list(plt.xticks()[0]) + [0.49])\n",
    "plt.yticks(list(plt.yticks()[0]) + [0.846])\n",
    "\n",
    "# Colorer le tick x = 0.49 en rouge\n",
    "for label in plt.gca().get_xticklabels():\n",
    "    if label.get_text() == '0.49':\n",
    "        label.set_color('red')\n",
    "\n",
    "# Colorer le tick y = 0.8421 en rouge\n",
    "for label in plt.gca().get_yticklabels():\n",
    "    if label.get_text() == '0.846':\n",
    "        label.set_color('red')\n",
    "plt.xlim(0, 1)\n",
    "plt.ylim(0.55, 0.87)\n",
    "plt.grid()\n",
    "plt.xlabel(\"Ratio\\n(0 = text only // 1 = image only)\")\n",
    "plt.ylabel(\"Exactitude (données de validation)\")\n",
    "plt.title(\"Weighted voter - Exactitude en fonction du poids texte/image\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3761af7-4a79-4ed8-ac28-1e45fe47adfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ratio |accuracy\")\n",
    "print(\"------+--------\")\n",
    "for al, ac in accuracies[40:60]:\n",
    "    print(f\"{al:.2f}  | {100*ac:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7c3193d-e537-4009-9510-71a0ed88b314",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.49\n",
    "multimodal_voter = ModelWrapperFactory.make_mmo_voter_wrapper(\n",
    "    name=\"0.49-Weighted Voter\",\n",
    "    model_wrappers=[txt_model, img_model],\n",
    "    agg_fn=AGG_FN.WEIGHTED,\n",
    "    weights = [alpha, 1-alpha]\n",
    ")\n",
    "\n",
    "multimodal_voter.visual_report()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9ef476b-37a3-41e9-9004-9a8e6491c55e",
   "metadata": {},
   "source": [
    "## 6. Pondération par classe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79255c80-9ee0-4fd5-8f46-c61ee6f610de",
   "metadata": {},
   "outputs": [],
   "source": [
    "multimodal_voter = ModelWrapperFactory.make_mmo_voter_wrapper(\n",
    "    name=\"Class-Weighted Voter\",\n",
    "    model_wrappers=[txt_model, img_model],\n",
    "    agg_fn=AGG_FN.CLASS_WEIGHTED,\n",
    "    weights=[\n",
    "        txt_model.performance_summary.precisions,\n",
    "        img_model.performance_summary.precisions]\n",
    ")\n",
    "multimodal_voter.visual_report()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d13f29c-d7e7-4482-909e-346bb078248e",
   "metadata": {},
   "outputs": [],
   "source": [
    "txt_weights = np.array(txt_model.performance_summary.precisions)\n",
    "img_weights = np.array(img_model.performance_summary.precisions)\n",
    "summed_weights = txt_weights + img_weights\n",
    "txt_weights /= summed_weights\n",
    "img_weights /= summed_weights\n",
    "\n",
    "indices = np.arange(len(txt_weights))\n",
    "\n",
    "plt.bar(indices, np.ones(16), alpha = 0.75) # pour \"sauter la couleur bleue et retrouver les couleurs des graphes précédents\n",
    "plt.bar(indices, img_weights, bottom=txt_weights, label='image model', alpha = 0.75)\n",
    "plt.bar(indices, txt_weights, label='text model', alpha = 0.75)\n",
    "\n",
    "plt.ylabel('Poids')\n",
    "plt.xlabel('Classe')\n",
    "plt.title('Valeurs des poids par classe associés aux modèles constitutifs')\n",
    "plt.xticks(indices)\n",
    "plt.ylim(0, 1.05)\n",
    "plt.legend(loc='lower right')\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "837f8315-14db-4561-b03f-1da40a981395",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\" class | txt weight | img weight \")\n",
    "print(\"-------+------------+------------\")\n",
    "for c, (t, i) in enumerate(zip(txt_weights, img_weights)):\n",
    "    print(f\"   {c:02d}  |    {t:.2f}    |    {i:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34b86431-ff8e-4a38-a237-602763a3ef79",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
