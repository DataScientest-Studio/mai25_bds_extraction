{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3926962c-1175-4364-a47d-c344a28a103b",
   "metadata": {},
   "source": [
    "# Extraction des premières données"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69b766ee-1acb-4246-a6c5-ce034b196e95",
   "metadata": {},
   "source": [
    "## 1. Préparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27a80f19-05e8-400a-9cfa-78c06ae1cbb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image, UnidentifiedImageError\n",
    "from PIL.TiffTags import TAGS\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.ndimage import gaussian_filter, laplace\n",
    "from scipy.stats import entropy as scipy_entropy\n",
    "import cv2\n",
    "import time\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "project_root = Path().resolve().parent\n",
    "if not project_root in [Path(p).resolve() for p in sys.path]:\n",
    "    sys.path.append(str(project_root))\n",
    "\n",
    "from src import PATHS\n",
    "\n",
    "df = pd.read_parquet(os.path.join(PATHS.metadata, \"df_filename_relative_path.parquet\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1ec54b0-a2d9-45b4-9712-b3f3463337e2",
   "metadata": {},
   "source": [
    "## 2. Ecriture de fonctions pour extraire:\n",
    "- la largeur\n",
    "- la netteté (avec la variance du laplacien, normalisee par le nombre de pixels de l'image)\n",
    "- le bruit (on lisse l'image avec un blur gaussien et on compare à l'image initiale)\n",
    "- le ratio de pixels blancs (valeur > 200)\n",
    "- le ratio de pixels noirs (valeur < 50)\n",
    "- la taille des bords/marges de façon à pouvoir les retirer lors du preprocessing\n",
    "- le nombre de lignes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6525b65-5f2e-49f0-849c-77b8959349f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nettete(img):\n",
    "    \"\"\"\n",
    "    Mesure la netteté via la variance du Laplacien, normalisée par le nombre de pixels.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        lap = laplace(img)\n",
    "        return np.var(lap) / img.size\n",
    "    except Exception as e:\n",
    "        print(\"Erreur dans nettete():\", e)\n",
    "        return None\n",
    "\n",
    "def bruit(img):\n",
    "    \"\"\"\n",
    "    Estime le bruit en comparant l'image à une version lissée avec un filtre gaussien.\n",
    "    \"\"\"\n",
    "    sigma=1.0\n",
    "    if img is None:\n",
    "        raise ValueError(f\"Impossible de lire l'image : {file_path}\")\n",
    "    img = img.astype(np.float32)\n",
    "    smoothed = cv2.GaussianBlur(img, (0, 0), sigma)\n",
    "    noise = img - smoothed\n",
    "    return np.std(noise)\n",
    "\n",
    "def ratio_b(img):\n",
    "    \"\"\"\n",
    "    Retourne le ratio de pixels dont la valeur est supérieure à 200 (pixels blancs).\n",
    "    \"\"\"\n",
    "    white_pixels = np.sum(img > 200)\n",
    "    return white_pixels / img.size\n",
    "\n",
    "def ratio_n(img):\n",
    "    \"\"\"\n",
    "    Retourne le ratio de pixels dont la valeur est inférieure à 50 (pixels noirs).\n",
    "    \"\"\"\n",
    "    black_pixels = np.sum(img < 50)\n",
    "    return black_pixels / img.size\n",
    "\n",
    "def entropy(img):\n",
    "    \"\"\"\n",
    "    Calcule l'entropie d'une image en niveaux de gris à partir d'un fichier image.\n",
    "\n",
    "    L'entropie est une mesure statistique qui quantifie la quantité d'information\n",
    "    ou la complexité présente dans l'image. Plus l'entropie est élevée, plus\n",
    "    l'image contient de détails ou de variations.\n",
    "\n",
    "    Cette fonction lit l'image en utilisant OpenCV en mode niveaux de gris,\n",
    "    calcule son histogramme normalisé des intensités de pixel, puis calcule\n",
    "    l'entropie de cette distribution.\n",
    "\n",
    "    Paramètres:\n",
    "    -----------\n",
    "    file_path : str\n",
    "        Chemin vers le fichier image à analyser.\n",
    "    resize_max_dim : int ou None, optionnel (par défaut None)\n",
    "        Si spécifié, redimensionne l'image pour que la plus grande dimension\n",
    "        soit égale à cette valeur, afin d'accélérer le calcul sur les grandes images.\n",
    "\n",
    "    Retour:\n",
    "    --------\n",
    "    float\n",
    "        Valeur de l'entropie de l'image (en nats).\n",
    "\n",
    "    \"\"\"\n",
    "    if img is None:\n",
    "        raise ValueError(f\"Impossible de lire l'image : {file_path}\")\n",
    "    # Pas besoin de .load(), img est déjà un np.array\n",
    "    hist, _ = np.histogram(img, bins=256, range=(0, 255), density=True)\n",
    "    hist = hist[hist > 0]\n",
    "    return scipy_entropy(hist)\n",
    "\n",
    "def compression(img):\n",
    "    \"\"\"\n",
    "    Récupère les informations de compression d'une image.\n",
    "\n",
    "    Retourne :\n",
    "    - Le type de compression utilisé dans le fichier (ex: 'packbits', 'jpeg', None, etc.)\n",
    "    - Un ratio de compression approximatif (taille fichier / taille brute image)\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    file_path : str\n",
    "        Chemin vers le fichier image.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    tuple (str or None, float)\n",
    "        (compression_type, compression_ratio)\n",
    "    \"\"\"\n",
    "    compression_type = img.info.get('compression', None)\n",
    "    width, height = img.size\n",
    "    channels = len(img.getbands())\n",
    "    # Hypothèse : 1 octet par canal (ex: mode 'L', 'RGB')\n",
    "    depth_bytes = 1\n",
    "    uncompressed_size = width * height * channels * depth_bytes\n",
    "\n",
    "    file_size = os.path.getsize(file_path)\n",
    "    compression_ratio = file_size / uncompressed_size if uncompressed_size > 0 else None\n",
    "\n",
    "    return compression_type, compression_ratio\n",
    "\n",
    "\n",
    "def resolution(img):\n",
    "    #Extrait la résolution (DPI) horizontale et verticale d'une image.\n",
    "    #Retourne (dpi_x, dpi_y) si disponible, sinon (np.nan, np.nan).\n",
    "    \n",
    "    try:\n",
    "        dpi = img.info.get('dpi')\n",
    "        if isinstance(dpi, (tuple, list)) and len(dpi) == 2:\n",
    "            return dpi[0], dpi[1]\n",
    "    except Exception as e:\n",
    "        pass  # ou log l'erreur si besoin\n",
    "\n",
    "    return np.nan, np.nan\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be728766-158d-4e81-a0e0-d0ed73d8aa83",
   "metadata": {},
   "outputs": [],
   "source": [
    "def marges(img):\n",
    "    \"\"\"\n",
    "    Détecte les marges haut, bas, gauche, droite d'une image TIFF en mode L.\n",
    "\n",
    "    Params:\n",
    "        image_path (str): chemin vers l'image .tiff\n",
    "    Returns:\n",
    "        top, bottom, left, right: tailles des marges en pixels\n",
    "    \"\"\"\n",
    "    # 1. récupérer l'image\n",
    "    img_np = np.array(img)\n",
    "    height, width = img_np.shape\n",
    "    \n",
    "    # Filtre médian pour réduire le bruit ponctuel\n",
    "    denoised = cv2.medianBlur(img_np, ksize=5)  # ksize impair, typiquement 3 ou 5\n",
    "\n",
    "    # Floutage gaussien pour lisser avant seuillage\n",
    "    blurred = cv2.GaussianBlur(denoised, (5, 5), 0)\n",
    "\n",
    "    # Binarisation adaptative sur image débruitée\n",
    "    binary = cv2.adaptiveThreshold(\n",
    "        blurred, 255,\n",
    "        cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
    "        cv2.THRESH_BINARY_INV,\n",
    "        blockSize=25,\n",
    "        C=15\n",
    "    )\n",
    "    \n",
    "    # 4. Projections\n",
    "    rows_sum = binary.sum(axis=1)\n",
    "    cols_sum = binary.sum(axis=0)\n",
    "    # Filtrer les lignes à analyser\n",
    "    top_bottom_ignore = 30\n",
    "    side_ignore=50 \n",
    "    # On enlève les bords parce qu'il peut y avoir des traits noirs dus à un scan de mauvaise qualité\n",
    "    valid_rows = rows_sum[top_bottom_ignore:height - top_bottom_ignore]\n",
    "    valid_cols = cols_sum[side_ignore:width - side_ignore]\n",
    "\n",
    "    if valid_rows.max() == 0 or valid_cols.max() == 0:\n",
    "        # Aucun texte détecté\n",
    "        return {'top': 0, 'bottom': height, 'left': 0, 'right': width}\n",
    "\n",
    "    # Marges haut/bas (avec décalage)\n",
    "    top = np.argmax(valid_rows > 0) + top_bottom_ignore\n",
    "    bottom = height - top_bottom_ignore - np.argmax(valid_rows[::-1] > 0)\n",
    "\n",
    "    # Marges gauche/droite (avec décalage)\n",
    "    left = np.argmax(valid_cols > 0) + side_ignore\n",
    "    right = width - side_ignore - np.argmax(valid_cols[::-1] > 0)\n",
    "\n",
    "    return top, bottom,  left, right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b39fe39-f28a-4b03-91bf-f64c61ed1daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pour récupérer le nombre de lignes\n",
    "def merge_close_lines(lines, min_distance):\n",
    "    \"\"\"\n",
    "    Fusionne les lignes trop proches les unes des autres.\n",
    "    \"\"\"\n",
    "    if not lines:\n",
    "        return []\n",
    "\n",
    "    merged = [lines[0]]\n",
    "    \n",
    "    for start, end in lines[1:]:\n",
    "        prev_start, prev_end = merged[-1]\n",
    "        if start - prev_end < min_distance:\n",
    "            # Fusionner avec la précédente\n",
    "            merged[-1] = (prev_start, end)\n",
    "        else:\n",
    "            merged.append((start, end))\n",
    "    return merged\n",
    "\n",
    "\n",
    "def show_detection_nb_lignes(img, show=True, debug=False):\n",
    "    \"\"\"\n",
    "    Détecte et (optionnellement) affiche les lignes de texte dans une image en niveaux de gris.\n",
    "\n",
    "    Params:\n",
    "        img (ndarray): Image (déjà rognée) en niveaux de gris.\n",
    "        show (bool): Affiche l’image avec les lignes détectées si True.\n",
    "        debug (bool): Affiche aussi le profil de projection si True.\n",
    "\n",
    "    Returns:\n",
    "        lines (List of tuples): liste de tuples (start_row, end_row) pour chaque ligne détectée.\n",
    "    \"\"\"\n",
    "    img_np = np.array(img)\n",
    "\n",
    "    # Binarisation (texte noir sur fond blanc)\n",
    "    _, binary = cv2.threshold(img_np, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "    binary_inv = 255 - binary  # Texte = 255 maintenant\n",
    "\n",
    "    # Morphologie verticale\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (1, 5))\n",
    "    eroded = cv2.erode(binary_inv, kernel, iterations=1)\n",
    "\n",
    "    # Profil de projection verticale\n",
    "    projection = np.sum(eroded // 255, axis=1)\n",
    "\n",
    "    # Seuil basé sur le percentile 95\n",
    "    max_proj = np.percentile(projection, 95)\n",
    "    threshold = max_proj * 0.25\n",
    "\n",
    "    # Détection des lignes\n",
    "    lines = []\n",
    "    in_line = False\n",
    "    start = 0\n",
    "\n",
    "    for i, val in enumerate(projection):\n",
    "        if val > threshold:\n",
    "            if not in_line:\n",
    "                start = i\n",
    "                in_line = True\n",
    "        else:\n",
    "            if in_line:\n",
    "                end = i\n",
    "                lines.append((start, end))\n",
    "                in_line = False\n",
    "    if in_line:\n",
    "        lines.append((start, len(projection)))\n",
    "\n",
    "    # Fusionner les lignes trop proches\n",
    "    lines = merge_close_lines(lines, min_distance=4)\n",
    "\n",
    "    # Affichage (si demandé)\n",
    "    if show:\n",
    "        fig, ax = plt.subplots(figsize=(8, 10))\n",
    "        ax.imshow(img_np, cmap='gray')\n",
    "        for start, end in lines:\n",
    "            rect = plt.Rectangle((0, start), img_np.shape[1], end - start,\n",
    "                                 linewidth=1, edgecolor='red', facecolor='none')\n",
    "            ax.add_patch(rect)\n",
    "        ax.set_title(f\"Lignes détectées : {len(lines)}\")\n",
    "        ax.axis('off')\n",
    "        plt.show()\n",
    "\n",
    "    if debug:\n",
    "        plt.figure(figsize=(8, 2))\n",
    "        plt.plot(projection)\n",
    "        plt.axhline(y=threshold, color='red', linestyle='--')\n",
    "        plt.title(\"Projection verticale des pixels noirs (profil)\")\n",
    "        plt.show()\n",
    "\n",
    "    return lines\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e1a57f2-8897-4fda-bdf9-a37ad135c71f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_detection_nb_colonnes(img, show=True, debug=False):\n",
    "    \"\"\"\n",
    "    Détecte et (optionnellement) affiche les colonnes de texte dans une image (numpy, niveaux de gris).\n",
    "\n",
    "    Params:\n",
    "        img (ndarray): Image en niveaux de gris (déjà rognée).\n",
    "        show (bool): Affiche l’image avec les colonnes détectées si True.\n",
    "        debug (bool): Affiche le profil de projection horizontal si True.\n",
    "\n",
    "    Returns:\n",
    "        columns (List of tuples): liste de tuples (start_col, end_col) pour chaque colonne détectée.\n",
    "    \"\"\"\n",
    "    img_np = np.array(img)\n",
    "\n",
    "    # Binarisation\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
    "    img_eq = clahe.apply(img_np)\n",
    "    _, binary = cv2.threshold(img_eq, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "    binary_inv = 255 - binary  # texte = 255\n",
    "\n",
    "    # Morphologie horizontale pour séparer les colonnes (éventuellement)\n",
    "    kernel_width = max(10, img_eq.shape[1] // 100)\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (kernel_width, 1))\n",
    "    eroded = cv2.erode(binary_inv, kernel, iterations=1)\n",
    "\n",
    "    # Projection horizontale (sur les colonnes)\n",
    "    window = 50\n",
    "    proj = np.sum(eroded // 255, axis=0)\n",
    "    projection = np.convolve(proj, np.ones(window)/window, mode='same')\n",
    "    \n",
    "\n",
    "    # Seuil pour distinguer une colonne active, selon le contraste\n",
    "    contrast = np.std(img_eq)\n",
    "    if contrast < 43:  # image très pâle\n",
    "        factor = 0.8\n",
    "    elif contrast < 70:  # contraste moyen\n",
    "        factor = 1.4\n",
    "    else:  # bon contraste\n",
    "        factor = 2\n",
    "    \n",
    "    mean_proj = np.mean(projection)\n",
    "    median_proj = np.median(projection)\n",
    "    threshold = min(mean_proj, median_proj) * factor\n",
    "    \n",
    "    columns = []\n",
    "    in_column = False\n",
    "    start = 0\n",
    "\n",
    "    for i, val in enumerate(projection):\n",
    "        if val > threshold:\n",
    "            if not in_column:\n",
    "                start = i\n",
    "                in_column = True\n",
    "        else:\n",
    "            if in_column:\n",
    "                end = i\n",
    "                columns.append((start, end))\n",
    "                in_column = False\n",
    "    if in_column:\n",
    "        columns.append((start, len(projection)))\n",
    "\n",
    "    # Fusionner les colonnes trop proches (si nécessaire)\n",
    "    min_dist = img_np.shape[1] // 40\n",
    "    columns = merge_close_lines(columns, min_distance=min_dist)\n",
    "    #columns = merge_close_lines(columns, min_distance=20)\n",
    "\n",
    "    # Enlever les colonnes trop fines\n",
    "    min_width = 30 #pixels\n",
    "    columns = [(start, end) for (start, end) in columns if (end - start) > min_width]\n",
    "    \n",
    "    # Affichage (si demandé)\n",
    "    if show:\n",
    "        fig, ax = plt.subplots(figsize=(10, 8))\n",
    "        ax.imshow(img_np, cmap='gray')\n",
    "        for start, end in columns:\n",
    "            rect = plt.Rectangle((start, 0), end - start, img_np.shape[0],\n",
    "                                 linewidth=1, edgecolor='blue', facecolor='none')\n",
    "            ax.add_patch(rect)\n",
    "        ax.set_title(f\"Colonnes détectées : {len(columns)}\")\n",
    "        ax.axis('off')\n",
    "        plt.show()\n",
    "\n",
    "    if debug:\n",
    "        plt.figure(figsize=(8, 2))\n",
    "        plt.plot(projection)\n",
    "        plt.axhline(y=threshold, color='blue', linestyle='--')\n",
    "        plt.title(\"Projection horizontale des pixels noirs (profil)\")\n",
    "        plt.show()\n",
    "\n",
    "    return columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57adb4f7-6811-4527-bfa5-83047718bafe",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 4. Test sur 1 image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7df3e75-906f-4410-9145-e7415e1a58f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## On teste sur 1 image\n",
    "relative_filepath, filename = df.iloc[0, :]\n",
    "file_path = os.path.join(rvl_cdip_images_path, relative_filepath, filename)\n",
    "print(file_path)\n",
    "img = cv2.imread(file_path, cv2.IMREAD_GRAYSCALE)\n",
    "print(\"Nettete :\", nettete(img))\n",
    "print(\"Bruit :\", bruit(img))\n",
    "print(\"Ratio_b :\", ratio_b(img))\n",
    "print(\"Ratio_n :\", ratio_n(img))\n",
    "print(\"Entropie :\", entropy(img))\n",
    "\n",
    "with Image.open(file_path) as img:\n",
    "    print(\"Resolution_x:\", resolution(img)[0])\n",
    "    print(\"Resolution_y:\", resolution(img)[1])\n",
    "    print(\"Compression:\",compression(img)[1])\n",
    "    print(\"Format:\", img.format)\n",
    "    print(\"Size:\", img.size)\n",
    "    print(\"Mode:\", img.mode)\n",
    "    #print(\"DPI:\",img.info.get('dpi')) #c'est la résolution\n",
    "\n",
    "    # Attributes and methods\n",
    "    #print(\"\\nAttributes and methods list:\")\n",
    "    #print(dir(img))\n",
    "\n",
    "    # Attributes\n",
    "    #print(\"\\nAttributes:\")\n",
    "    #for key, value in img.__dict__.items():\n",
    "    #    print(f\"{key}: {value}\")\n",
    "\n",
    "    # Metadata tags\n",
    "    #print(\"\\nTIFF Metadata:\")\n",
    "    #for tag, value in img.tag.items():\n",
    "    #    tag_name = TAGS.get(tag, tag)\n",
    "    #    print(f\"{tag_name}: {value}\")\n",
    "\n",
    "\n",
    "# VOIR ICI pour tout ce que l'on peut extraire: https://pillow.readthedocs.io/en/stable/reference/Image.html#PIL.Image.Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "772db7ec-99c5-4bea-b668-fd89a34cd6e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_original_and_cropped(img, cropped):\n",
    "    \"\"\"\n",
    "    Affiche l'image d'origine et l'image recadrée sans les marges détectées.\n",
    "    Ajoute une bordure noire autour des images pour visualiser les bords.\n",
    "\n",
    "    Params:\n",
    "        image_path (str): Chemin vers l'image TIFF\n",
    "        border (int): Épaisseur de la bordure noire (en pixels)\n",
    "    \"\"\"\n",
    "\n",
    "    # 4. Ajouter un liseré noir autour des images\n",
    "    border=5\n",
    "    original_bordered = np.pad(img, pad_width=border, mode='constant', constant_values=0)\n",
    "    cropped_bordered = np.pad(cropped, pad_width=border, mode='constant', constant_values=0)\n",
    "\n",
    "    # 5. Afficher les deux images côte à côte\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(12, 6))\n",
    "\n",
    "    axes[0].imshow(original_bordered, cmap='gray', vmin=0, vmax=255)\n",
    "    axes[0].set_title(\"Image originale\")\n",
    "    axes[0].axis('off')\n",
    "\n",
    "    axes[1].imshow(cropped_bordered, cmap='gray', vmin=0, vmax=255)\n",
    "    axes[1].set_title(\"Image sans marges\")\n",
    "    axes[1].axis('off')\n",
    "    \n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8865eba3-fa1c-4857-9c4f-29deb235c576",
   "metadata": {},
   "outputs": [],
   "source": [
    "relative_filepath, filename = df.iloc[5, :]\n",
    "file_path = os.path.join(rvl_cdip_images_path, relative_filepath, filename)\n",
    "print(file_path, filename)\n",
    "img = cv2.imread(file_path, cv2.IMREAD_GRAYSCALE)\n",
    "# 2. Détection des marges\n",
    "top, bottom, left, right = marges(img)  # marges est ta fonction\n",
    "# 3. Recadrer l'image selon les marges\n",
    "cropped = img[top:bottom, left:right]\n",
    "#show_original_and_cropped(img, cropped)\n",
    "\n",
    "#on lave un peu l'image...\n",
    "img_np = np.array(cropped)\n",
    "height, width = img_np.shape\n",
    "\n",
    "#on regarde le contraste\n",
    "print(\"Contraste : \", np.std(img_np))\n",
    "\n",
    "# Filtre médian pour réduire le bruit ponctuel\n",
    "denoised = cv2.medianBlur(img_np, ksize=3)  # ksize impair, typiquement 3 ou 5\n",
    "\n",
    "# Floutage gaussien pour lisser avant seuillage\n",
    "blurred = cv2.GaussianBlur(denoised, (3,3), 0)\n",
    "\n",
    "lines = show_detection_nb_lignes(blurred, show=False)\n",
    "print(\"nombre de lignes :\", len(lines))\n",
    "\n",
    "colonnes = show_detection_nb_colonnes(denoised, show=True)\n",
    "print(\"nombre de colonnes :\", len(colonnes))\n",
    "colonnes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b922193a-067c-4286-b24d-0be1b6a9ee68",
   "metadata": {},
   "source": [
    "## 5. Extraction sur toutes les images et création d'un .parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bd3db1e-d5dc-4942-9ad9-f534453b4396",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_data(row):\n",
    "    relative_filepath, filename = row[\"relative_path\"], row[\"filename\"]\n",
    "    file_path = os.path.join(rvl_cdip_images_path, relative_filepath, filename)\n",
    "    img = cv2.imread(file_path, cv2.IMREAD_GRAYSCALE)\n",
    "    try:\n",
    "        Nettete = nettete(img)\n",
    "        Bruit = bruit(img)\n",
    "        Ratio_b = ratio_b(img)\n",
    "        Ratio_n = ratio_n(img)\n",
    "        Entropie = entropy(img)\n",
    "        top, bottom, left, right = marges(img)\n",
    "        # Recadrer l'image selon les marges\n",
    "        cropped = img[top:bottom, left:right]\n",
    "        img_np = np.array(cropped)\n",
    "        height, width = img_np.shape\n",
    "        # Filtre médian pour réduire le bruit ponctuel\n",
    "        denoised = cv2.medianBlur(img_np, ksize=3)  # ksize impair, typiquement 3 ou 5\n",
    "        # Floutage gaussien pour lisser\n",
    "        blurred = cv2.GaussianBlur(denoised, (3,3), 0)\n",
    "        lines = show_detection_nb_lignes(blurred, show=False)\n",
    "        nb_lignes = len(lines)\n",
    "        colonnes = show_detection_nb_colonnes(denoised, show=False)\n",
    "        nb_colonnes = len(colonnes)\n",
    "        with Image.open(file_path) as img:\n",
    "            Compression = compression(img)[1]\n",
    "            #Resolution_x = resolution(img)[0] #fixé à 72 lors du preprocessing, valeur standard de rendu écran\n",
    "            #Resolution_y = resolution(img)[1] #fixé à 72 lors du preprocessing, valeur standard de rendu écran\n",
    "            #format_ = img.format #toujours des tiff, donc je ne le récupere pas \n",
    "            width = img.size[0] \n",
    "            #length = img.size[1]#length fixee à 1000 donc je ne la recupere pas \n",
    "            #mode = img.mode #toujours L donc je ne le récupere pas \n",
    "    except (UnidentifiedImageError, FileNotFoundError, OSError):\n",
    "        Nettete = Bruit = Ratio_b = Ratio_n = Entropie = Compression = width  = top = bottom = left = right = nb_lignes = nb_colonnes  = np.nan\n",
    "    return Nettete, Bruit, Ratio_b, Ratio_n, Entropie, Compression, width, top , bottom , left , right , nb_lignes , nb_colonnes\n",
    "\n",
    "\n",
    "def get_image_data_to_df(df):\n",
    "    def f(row):\n",
    "        relative_filepath, filename = row[\"relative_path\"], row[\"filename\"]\n",
    "        file_path = os.path.join(rvl_cdip_images_path, relative_filepath, filename)\n",
    "        return get_image_data(row)\n",
    "    return pd.DataFrame(\n",
    "        df.apply(f, axis = 1).tolist(),\n",
    "        columns = [\"Nettete\", \"Bruit\", \"Ratio_b\", \"Ratio_n\", \"Entropie\", \"Compression\", \"width\", \n",
    "                   \"top_marge\", \"bottom_marge\", \"left_marge\", \"right_marge\", \"nb_lignes\", \"nb_colonnes\"],\n",
    "        index = df.index\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6ae4ce6-956f-4268-940a-a1e616dd7248",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bon la parallélisation ne fonctionne pas donc, pour le moment, je lance sans paralléliser\n",
    "# Normalement, ça devrait tourner 16h, mais pas beaucoup plus, sinon, il y a un souci...\n",
    "\n",
    "t0 = time.time()\n",
    "df_results = get_image_data_to_df(df)\n",
    "df = pd.concat([df, df_results], axis=1)\n",
    "print(f\"Durée d'exécution: {time.time() - t0:.2f} secondes pour {len(df)} images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97be9ad6-765e-4c90-882d-be2a8f53f47a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "125f9b2a-54f4-4b70-ac71-619e6ea67b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.drop(columns=['path', 'relative_path', 'filename'])\n",
    "df.to_parquet(os.path.join(PATHS.metadata, \"df_features.parquet\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b6b5183-4c95-46da-b7ff-6de5783e3c5e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
