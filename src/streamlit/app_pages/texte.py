import streamlit as st
import pandas as pd
import numpy as np
import os
import re
import base64
import io
from PIL import Image
import matplotlib.pyplot as plt
import seaborn as sns
from assets import PATHS
from assets import style
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.naive_bayes import MultinomialNB
from sklearn.metrics import classification_report
# src/streamlit/app_pages/texte.py

sections = ["Preprocessing", "Machine Learning", "Deep Learning", "Evaluation"]  

section_counter = 0
def next_section():
    global section_counter
    st.markdown(f'<a name="{sections[section_counter]}"></a>', unsafe_allow_html=True)
    st.markdown(f"<hr style='{style.divider}'>",unsafe_allow_html=True)
    # st.markdown("""<div style="padding-top: 240px; margin-top: -240px;"></div>""",unsafe_allow_html=True)
    st.header(sections[section_counter])
    section_counter += 1

def show():

    st.title("ðŸ“„ Analyse Textuelle des Documents OCR")

    st.header("ðŸŽ¯ Objectif du projet")
    st.markdown("""
    PrÃ©traiter et analyser automatiquement un ensemble de documents OCR pour :
    - Nettoyer les mÃ©tadonnÃ©es
    - Extraire du contenu textuel structurel
    - Identifier les entitÃ©s clÃ©s (noms, dates, organisationsâ€¦)
    - Classifier automatiquement les types de documents
    - Poser les bases pour des analyses NLP avancÃ©es
    """)

    # st.image(os.path.join(PATHS.streamlit, "assets", "images","pipeline.png"), caption="Objectif du pipeline", use_container_width=True)

    st.header("ðŸ§¹ PrÃ©traitement des donnÃ©es")
    st.markdown("""
    Les Ã©tapes principales du nettoyage ont Ã©tÃ© effectuÃ©es avec **Pandas** :
    - Suppression des doublons et lignes vides
    - Nettoyage des chaÃ®nes de caractÃ¨res (`None`, espaces, casse)
    - Parsing des dates (`document_date`, `scan_date`)
    - Nettoyage des champs textuels (`title`, `ocr_text`, `author`)
    - Standardisation des types de documents (`dt`)
    - Conversion des champs numÃ©riques (`pages_amount`, `np`, etc.)
    """)
    st.image(os.path.join(PATHS.streamlit, "assets", "images","dfocr.png"), caption="DF Avant aprÃ¨s", use_container_width=True)

    st.subheader("ðŸ”§ ProblÃ¨mes rencontrÃ©s")
    st.markdown("""
    Certains jeux de donnÃ©es Ã©taient trÃ¨s hÃ©tÃ©rogÃ¨nes :
    - Valeurs manquantes frÃ©quentes
    - DonnÃ©es bruyantes ou mal OCRisÃ©es
    - IncohÃ©rences dans les mÃ©tadonnÃ©es
    """)
    st.image(os.path.join(PATHS.streamlit, "assets", "images","pb_rencontre.png"), caption="Ocr handwritten", use_container_width=True)
    st.image(os.path.join(PATHS.streamlit, "assets", "images","valeurs manquantes.png"), caption="Valeurs manquantes", use_container_width=True)
    st.header("ðŸ§  Extraction automatique du contenu")
    st.markdown("""
    Les Ã©tapes dâ€™analyse de texte comprennent :
    - **Tokenisation** avec POS-tagging et lemmatisation
    - **Segmentation en phrases** : pour prÃ©paration au rÃ©sumÃ© ou Ã  la structuration
    - **Stop words plus suppression caractÃ¨res trop reccurents (pgnbr,html, etc.)**
    """)

    st.header("ðŸ§ª ModÃ©lisation : Classification des types de documents")
    st.subheader("Pipeline ML (modÃ¨les classiques)")
    st.markdown("""
    1. **TF-IDF Vectorization**
    2. **Logistic Regression**
    3. **Ã‰valuation (train/test split)**
    4. **Analyse des rÃ©sultats**
    """)

    st.image(os.path.join(PATHS.streamlit, "assets", "images","vecteur.png"), caption="Ocr handwritten", use_container_width=True)

    st.subheader("ðŸ“Š RÃ©sultats")
    st.markdown("Les performances varient selon la source des donnÃ©es. Deux jeux sur trois ont Ã©tÃ© retenus pour lâ€™expÃ©rimentation.")
    st.markdown("Un pipeline complet a Ã©tÃ© conÃ§u pour automatiser tout le processus :")
    st.markdown("- Nettoyage â†’ Vectorisation â†’ ModÃ¨le â†’ PrÃ©diction")

    st.header("ðŸ“ˆ ModÃ¨les Classiques : Comparaison")

    ### Logistic Regression
    st.subheader("ðŸ”¹ RÃ©gression Logistique")

    st.image(os.path.join(PATHS.streamlit, "assets", "images","REG LOG.png"), caption="Resultats Regression logistique", use_column_width=True)

    st.markdown("""
    - **Accuracy** : 82%
    - **F1 macro** : 82%
    - Classes bien identifiÃ©es : `2`, `7`, `14`
    - Classe difficile : `3` (handwritten)

    | Classe | PrÃ©cision | Rappel | F1-Score | Commentaire |
    |--------|-----------|--------|----------|-------------|
    | 2      | 0.95      | 0.91   | 0.93     | Excellent   |
    | 3      | 0.62      | 0.76   | 0.68     | AmbiguÃ«     |
    | 8      | 0.63      | 0.81   | 0.71     | PrÃ©cision faible |
    """)


    ### Random Forest
    st.subheader("ðŸ”¸ Random Forest")
    st.image(os.path.join(PATHS.streamlit, "assets", "images","Random Forest.png"), caption="Resultats Random Forest", use_column_width=True)

    st.markdown("""
    - **Accuracy** : 82%
    - **F1 macro** : 82%
    - Moins interprÃ©table mais robuste
    - RÃ©sultats plus variÃ©s selon les classes

    | Classe | PrÃ©cision | Rappel | F1-Score | Commentaire |
    |--------|-----------|--------|----------|-------------|
    | 14     | 0.98      | 0.97   | 0.98     | Quasi parfaite |
    | 3      | 0.56      | 0.75   | 0.64     | Confusion forte |
    """)

    ### Naive Bayes
    st.subheader("âšª Naive Bayes")
    st.image(os.path.join(PATHS.streamlit, "assets", "images","result naive bayes.png"), caption="Resultats Naive Bayes", use_container_width=True)

    st.markdown("""
    - **Accuracy** : 68%
    - **F1 macro** : 67%
    - Bon sur classes claires, faible sur classes ambiguÃ«s

    | Classe | F1-Score | Commentaire |
    |--------|----------|-------------|
    | 2, 7, 14 | > 0.85 | Bonnes performances |
    | 3, 8    | < 0.60 | TrÃ¨s mal reconnues |
    """)
    st.image(os.path.join(PATHS.streamlit, "assets", "images","comparaison metriques graphique.png"), caption="Ocr handwritten", use_container_width=True)

    st.header("ðŸ§  Deep Learning sur le texte (MLP)")

    st.markdown("""
    - Texte encodÃ© avec **Tokenizer Keras** â†’ SÃ©quences entiÃ¨res
    - Padding Ã  longueur fixe (300)
    - Architecture simple avec :
        - Embedding
        - GlobalAveragePooling1D
        - Dense (ReLU + Dropout)
        - Softmax final
    """)


    st.subheader("ðŸ“‰ RÃ©sultats")

    st.image(os.path.join(PATHS.streamlit, "assets", "images","resultat dl.jpg"), caption="Objectif du pipeline", use_container_width=True)
    st.image(os.path.join(PATHS.streamlit, "assets", "images","Matrice confusion mlp.png"), caption="Objectif du pipeline", use_container_width=True)

    st.markdown("""
    - **Accuracy** : 81%
    - Classes trÃ¨s bien apprises : `2`, `7`, `14`
    - Confusion sur : `3`, `8`, `15`
    """)

    st.markdown("""
    | Classe | PrÃ©cision | Rappel | F1-score | Support | Commentaire |
    |--------|-----------|--------|----------|---------|-------------|
    | 2      | 0.92      | 0.92   | 0.92     | 2515    | Excellent |
    | 3      | 0.65      | 0.68   | 0.67     | 2230    | AmbiguÃ« et bruitÃ©e |
    | 8      | 0.65      | 0.66   | 0.65     | 1298    | Peut-Ãªtre Ã  traiter via multimodal |
    """)

    st.image(os.path.join(PATHS.streamlit, "assets", "images","courbe de perte mlp.png"), caption="Resultats Regression logistique", use_container_width=True)

    st.header("ðŸ§¾ Conclusion")
    st.markdown("""
    - Le **MLP** offre des performances solides (F1 macro = 81%).
    - Les modÃ¨les **classiques** (Logistic Regression, RF) sont performants, rapides et interprÃ©tables.
    - Le **Naive Bayes** reste utile pour des cas simples.
    - Des pistes dâ€™amÃ©lioration sont possibles :
        - LSTM, BERT
        - Ajout de mÃ©tadonnÃ©es
        - Approche **multimodale**
    """)